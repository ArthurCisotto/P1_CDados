{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Arthur Cisotto Machado\n",
    "\n",
    "Nome: Alessandra Yumi Carvalho Ogawa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONTEXTO DO PROJETO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A empresa de streaming *Netflix* em parceria com o estúdio espanhol *Vancouver Media* deseja saber e analisar como a audiencia está reagindo a série de sucesso *La Casa de Papel* na rede social Twitter. \n",
    "O projeto exige a criação de um programa que consiga classificar os tweets entre **relevantes** ou **irrelevantes** para a análise da empresa.\n",
    "\n",
    "A classificação foi feita com o intúito de ajudar a área de marketing das duas empresas parceiras a acharem comentários que possam ser úteis em algum sentido estratégio para mudança de operações internas e também como fonte de *feedback* em relação ao conteúdo cinematográfico produzido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### CARREGANDO AS BIBLIOTECAS UTILIZADAS NO RPOGRAMA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "import emoji\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "/Users/alessandrayumiogawa/Documents/INSPER/INSPER - 2A/C-DADOS/P1_CDados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### FUNÇÃO DE LIMPEZA DOS TWEETS:\n",
    "- tira sinais de pontuação irrelevantes para o texto;\n",
    "- todas as fontes são convertidas para letras minúsculas;\n",
    "- exculi repetição de emoji;\n",
    "- substitui emoji por seu código;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "\n",
    "    punctuation = '[”/-@\\\\n:;?\\\"\\'().,]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    text_split = text_subbed.split()\n",
    "    return ' '.join(text_split).lower()\n",
    "\n",
    "def limpa_emoji(tweet):\n",
    "    \n",
    "    modified=' '.join(emoji.get_emoji_regexp().split(tweet))\n",
    "    modified=modified.split()\n",
    "    for i,emoji1 in enumerate(modified):\n",
    "        if emoji1 in UNICODE_EMOJI['pt']:\n",
    "            modified[i]=UNICODE_EMOJI['pt'][emoji1].replace(':','')\n",
    "        elif emoji1 in UNICODE_EMOJI['en']:\n",
    "            modified[i]=UNICODE_EMOJI['en'][emoji1].replace(':','')\n",
    "        else:\n",
    "            continue\n",
    "    modified=' '.join(modified)\n",
    "        \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza_e_emoji(tweet):                 #compilado das duas funções em uma só para mais fácil aplicação\n",
    "    texto_filtrado = cleanup(tweet)\n",
    "    sem_emoji = limpa_emoji(texto_filtrado)\n",
    "    return sem_emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### CARREGANDO A BASE DE DADOS COM OS TWEETS CLASSIFICADOS COMO ***RELEVANTES*** E ***IRRELEVANTES*** MANUALMENTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'la casa de papel.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação do documento em dois DataFrames diferentes: **Treinamento** e **Teste**.\n",
    "\n",
    "- **Treinamento**: composto por 300 tweets classificados manualmente, será usado para *ensinar* o programa a classificar um tweets de acorodo com a sua relevância levando em conta as palavras em seu conteúdo.\n",
    "\n",
    "- **Teste**: composto por 200 tweets classificados manualmente, será usado para *testar* o programa classificador e comparar o resultado com a classificação feita à mão anteriormente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação (relevante = 1, não relevante = 0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tô vendo la casa de papel mdssss o primeiro ep...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agora vou assistir lá casa de papel e dormir p...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dedo coçando pra assistir lá casa de papel mas...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la casa de papel me faz torcer pros bandidos</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la casa de papel acabou comigo me encontro des...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  \\\n",
       "0  tô vendo la casa de papel mdssss o primeiro ep...   \n",
       "1  agora vou assistir lá casa de papel e dormir p...   \n",
       "2  dedo coçando pra assistir lá casa de papel mas...   \n",
       "3       la casa de papel me faz torcer pros bandidos   \n",
       "4  la casa de papel acabou comigo me encontro des...   \n",
       "\n",
       "   Classificação (relevante = 1, não relevante = 0)  \n",
       "0                                               1.0  \n",
       "1                                               0.0  \n",
       "2                                               0.0  \n",
       "3                                               1.0  \n",
       "4                                               1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train['Treinamento'] = train['Treinamento'].apply(limpeza_e_emoji) #aplicando a função de limpeza\n",
    "train.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS**: a função de limpeza já foi aplicada no DataFrame de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação (relevante = 1, não relevante = 0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quero terminar de ver a nova parte de la casa ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>não existe outra série no mundo que mexa comig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tá foda de desviar de todos os spoilers de la ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@todoroki_jun2 né tô me sentindo em lá casa de...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la casa de papel é tão ruim que nem consegui t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  \\\n",
       "0  quero terminar de ver a nova parte de la casa ...   \n",
       "1  não existe outra série no mundo que mexa comig...   \n",
       "2  tá foda de desviar de todos os spoilers de la ...   \n",
       "3  @todoroki_jun2 né tô me sentindo em lá casa de...   \n",
       "4  la casa de papel é tão ruim que nem consegui t...   \n",
       "\n",
       "   Classificação (relevante = 1, não relevante = 0)  \n",
       "0                                                 0  \n",
       "1                                                 1  \n",
       "2                                                 1  \n",
       "3                                                 0  \n",
       "4                                                 1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### CLASSIFICADOR AUTOMÁTICO DE SENTIMENTO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O filtro criado para a realização da classificação manual seguia o padrão especificado abaixo:\n",
    "\n",
    "**RELEVANTES**: As mensagens de texto com relevância mostravam a opinião e sentimentos, sejam eles positivos ou negativos, sobre a série.\n",
    "*Consideramos tweets relacionados a spoilers como relevantes pois eles também demonstram um forte sentimento que as pessoas possuem em relação à série.\n",
    "\n",
    "**IRRELEVANTES**: Classificamos como não relevantes tweets que não se encaixaram na nossa classificação de relevância, tweets que falavam sobre tópicos pessoais ou tweets que falavam sobre algum personagem específico da série.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### MONTANDO UM CLASSIFICADOR NAÏVE-BAYES:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PREPARANDO OS DADOS DO TREINAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando filtros para smeprar os tweets relevantes dos irrelevantes\n",
    "\n",
    "filtro_nao_relevante = train['Classificação (relevante = 1, não relevante = 0)']==0\n",
    "filtro_relevante = train['Classificação (relevante = 1, não relevante = 0)']==1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando em dois DFs diferentes os tweets relevantes e irrelevantes\n",
    "\n",
    "relevantes_train = train[filtro_relevante]\n",
    "nao_relevantes_train = train[filtro_nao_relevante]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando uma sting grande para armazenar todos os tweets de cada classificação\n",
    "\n",
    "relevantes_train_txt = ''\n",
    "for tweet in relevantes_train['Treinamento']:\n",
    "    relevantes_train_txt += \" \"\n",
    "    relevantes_train_txt += str(tweet)\n",
    "\n",
    "nao_relevantes_train_txt = ''\n",
    "for tweet in nao_relevantes_train['Treinamento']:\n",
    "    nao_relevantes_train_txt += \" \"\n",
    "    nao_relevantes_train_txt += str(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organizando os tweets em lista de palavras e pandas Series \n",
    "\n",
    "#fazendo a lista com todas as palavaras dos tweets\n",
    "todas_palavras_relevantes = relevantes_train_txt.split()\n",
    "todas_palavras_irrelevantes = nao_relevantes_train_txt.split()\n",
    "\n",
    "#transformando a lista em uma panda Series\n",
    "serie_relevante = pd.Series(todas_palavras_relevantes)\n",
    "serie_irrelevante = pd.Series(todas_palavras_irrelevantes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PREPARANDO AS TABELAS DE FREQUÊNCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relevante = serie_relevante.value_counts()\n",
    "tabela_irrelevante = serie_irrelevante.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que o conjunto universo seja apenas a soma de todas as palavras em tweets relevantes e irrelevantes, a seguir cria-se esse conjunto somando as strings de ambas. \n",
    "\n",
    "Além disso prossegu-se com o tratamento de dados criando uma lista com todas essas palavras e depois um pandas Series onde pode-se realizar a contagem da frequência de cada palavra e a partir daí começar o trinamento do programa partindo do conjunto universo de palavras.\n",
    "\n",
    "Para finalizar o tratamento do conjunto universo de palavras, cria-se uma lista de palavras excluindo as repetidas que serão usadas depois no método de ***Suavização de Laplace***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organizando o conjunto universo de todas as palavras\n",
    "\n",
    "palavras = relevantes_train_txt + nao_relevantes_train_txt\n",
    "todas_palavras = palavras.split()\n",
    "serie_palavras = pd.Series(todas_palavras)\n",
    "tabela_palavras = serie_palavras.value_counts(normalize=True)\n",
    "\n",
    "\n",
    "palavras_sem_repeticao = []\n",
    "for e in todas_palavras:\n",
    "    if e not in palavras_sem_repeticao:\n",
    "        palavras_sem_repeticao.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MONTANDO AS PROBABILIDADES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definindo os eventos:\n",
    "\n",
    "- $P(tweet|R)$: probabilidade de o tweet ser classificado como relevante;\n",
    "- $P(tweet|IR)$: probabilidade de o tweet ser classificado como irrelevante;\n",
    "- $P(R)$: probabilidade de um tweet ser relevante;\n",
    "- $P(IR)$: probabilidade de um tweet ser irrelevante;\n",
    "\n",
    "$$\\quad P(R) = \\frac{N palavras RELEVANTES}{N total palavras}$$  \n",
    "$$\\quad P(IR) = \\frac{N palavras IRRELEVANTES}{N total palavras}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculando a probabilidade de um tweet ser relevante ou irrelevante\n",
    "probR = len(serie_relevante)/len(serie_palavras)\n",
    "probIR = len(serie_irrelevante)/len(serie_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aplicação do Teorema de Bayes:\n",
    "\n",
    "Apresentação do teorema:\n",
    "$\\quad P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$  \n",
    "  \n",
    "Que nesse contexto seria equivalente à:  \n",
    "  \n",
    "$$\\quad P(R|tweet) = \\frac{P(tweet|R)P(R)}{P(tweet)}$$  \n",
    "$$\\quad P(IR|tweet) = \\frac{P(tweet|IR)P(IR)}{P(tweet)}$$  \n",
    "  \n",
    "É necessário realizar o cálculo de $P(tweet|R)$ e $P(tweet|IR)$ para aplicar o teorema e desse modo calcular a probbilidade de o tweet ser classificado como **relevante** ou **irrelevante**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRIMEIRA FUNÇÃO: calculando a probabilidade de uma X aparecer dado um dos conjuntos (relevante ou irrelevante)\n",
    "\n",
    "def probDadoconj(palavra, prob_conj, lista_palavras_conj):\n",
    "    if palavra in lista_palavras_conj:\n",
    "        return prob_conj[palavra]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#exemplo: print(probDadoconj(\"la\", tabela_relevante, todas_palavras_relevantes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suavização de Laplace (\"Laplace Soothing\"):\n",
    "\n",
    "Essa técnica é utilizada para evitar que uma probabilidade seja ZERO caso o Teorma de Bayes seja aplicado à uma amostra fora da base de dados que compõe o conjunto universo do que está sendo considerado a totalidade de palavras em tweets.  \n",
    "\n",
    "A possibilidade de resultar em zero vem do cálculo da probabilidade de um tweet ser classificado como relevante ou irrelevante já que é efetuada a multiplicação entre as probabilidades de cada palavra ser um indicador de relevância ou irrelevância.  \n",
    "\n",
    "Aplicando a suavização:\n",
    "$$\\quad P(palavra|conjunto) = \\frac{P(palavra|conjunto)+1}{palavras  conjunto + palavras sem repetição}$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEGUNDA FUNÇÃO: aplicando a suavização de Laplace\n",
    "\n",
    "def aplicando_laplace(prob_dado_conj, lista_palavras_conj):\n",
    "    return (prob_dado_conj+1)/(len(lista_palavras_conj)+len(palavras_sem_repeticao))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classificação final: \n",
    "\n",
    "Para realizar a classificação compila-se ambas as funções em uma só para que seja mais fácil de aplicar para todo o documento de tweets na base de treino.  \n",
    "\n",
    "Nela é calculada a probabilidade de um tweet ser classificado como relevante e como irrelevante e no fim é feita uma comparação retornando a classificação com maior probebilidade de ocorrer:  \n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(R|tweet) > P(IR|tweet)$, então o tweet será classificado como de **relevante**.\n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(IR|tweet) > P(R|tweet)$, então o tweet será classificado como de **irrelevante**.\n",
    "\n",
    "**Lembrando que**: a probabilidade é contruindo multiplicando a probabilidade de cada palavra na frase do tweet estar presente em relevância ou irrelevância:  \n",
    "\n",
    "$\\quad P(tweet|conj) = \n",
    "P(palavra1|conj)\\cdot P(palavra2|conj)\\cdot P(palavra3|conj)\\cdot P(palavra4|conj)\\cdot...$  \n",
    "\n",
    "E portanto a fórmula ficará:  \n",
    "\n",
    "$P(conj|tweet) = P(palavra1|conj)\\cdot P(palavra2|conj)\\cdot P(palavra3|conj)\\cdot P(palavra4|conj)\\cdot... P(conj)$  \n",
    "Vale ressaltar que a divisão por $P(tweet)$ não é necessária na hora de fazer a comparação uma vez que em ambas a probabilidades isso seria feito, então podemos tratá-lo como um fator comum no cálculo e desconsiderar a divisão por simplificação da fórmula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNÇÃO FINAL: compilado das duas funções anteriores\n",
    "#essa funçã0 realiza duas vezes as funções escritas anteriormente e depois comparam seus resultados para classificar\n",
    "\n",
    "def Classificacao(tweet):\n",
    "    prob_relevante = 1\n",
    "    lista_tweet = tweet.split()\n",
    "    for palavra in lista_tweet:\n",
    "        prob = probDadoconj(palavra, tabela_relevante, todas_palavras_relevantes)\n",
    "        prob_laplace = aplicando_laplace(prob, todas_palavras_relevantes)\n",
    "        prob_relevante *= prob_laplace\n",
    "    probRtweet = prob_relevante*probR\n",
    "    prob_irrelevante = 1\n",
    "    for palavra in lista_tweet:\n",
    "        prob = probDadoconj(palavra, tabela_irrelevante, todas_palavras_irrelevantes)\n",
    "        prob_laplace = aplicando_laplace(prob, todas_palavras_irrelevantes)\n",
    "        prob_irrelevante *= prob_laplace\n",
    "    probIRtweet = prob_irrelevante*probIR\n",
    "    if probRtweet < probIRtweet: \n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação (relevante = 1, não relevante = 0)</th>\n",
       "      <th>Classificacao_Naive_Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tô vendo la casa de papel mdssss o primeiro ep...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agora vou assistir lá casa de papel e dormir p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dedo coçando pra assistir lá casa de papel mas...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la casa de papel me faz torcer pros bandidos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la casa de papel acabou comigo me encontro des...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tô aqui assistindo la casa de papel mesmo depo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>eu achei que nenhuma morte de la casa de papel...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>caralho eu to chorando igual uma vagabunda com...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>cara eu nunca chorei tanto quanto eu chorei ol...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>o que caralhos foi isso em la casa de papel</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  \\\n",
       "0    tô vendo la casa de papel mdssss o primeiro ep...   \n",
       "1    agora vou assistir lá casa de papel e dormir p...   \n",
       "2    dedo coçando pra assistir lá casa de papel mas...   \n",
       "3         la casa de papel me faz torcer pros bandidos   \n",
       "4    la casa de papel acabou comigo me encontro des...   \n",
       "..                                                 ...   \n",
       "295  tô aqui assistindo la casa de papel mesmo depo...   \n",
       "296  eu achei que nenhuma morte de la casa de papel...   \n",
       "297  caralho eu to chorando igual uma vagabunda com...   \n",
       "298  cara eu nunca chorei tanto quanto eu chorei ol...   \n",
       "299        o que caralhos foi isso em la casa de papel   \n",
       "\n",
       "     Classificação (relevante = 1, não relevante = 0)  \\\n",
       "0                                                 1.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 1.0   \n",
       "4                                                 1.0   \n",
       "..                                                ...   \n",
       "295                                               0.0   \n",
       "296                                               1.0   \n",
       "297                                               1.0   \n",
       "298                                               1.0   \n",
       "299                                               1.0   \n",
       "\n",
       "     Classificacao_Naive_Bayes  \n",
       "0                            1  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            1  \n",
       "4                            1  \n",
       "..                         ...  \n",
       "295                          0  \n",
       "296                          1  \n",
       "297                          1  \n",
       "298                          1  \n",
       "299                          1  \n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Classificacao_Naive_Bayes'] = train.Treinamento.apply(Classificacao)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo foi de:  94.0 %\n"
     ]
    }
   ],
   "source": [
    "#Porcentagem de acerto de acerto no conjunto de Treino:\n",
    "\n",
    "tp=train.loc[(train['Classificacao_Naive_Bayes']==1)&(train['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\n",
    "tn=train.loc[(train['Classificacao_Naive_Bayes']==0)&(train['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\n",
    "print('A acurácia do modelo foi de: ',100*(tp+tn)/train.shape[0],'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### BASE DE TESTE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando a performance do Classificador \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação (relevante = 1, não relevante = 0)</th>\n",
       "      <th>Classificacao_Naive_Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quero terminar de ver a nova parte de la casa ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>não existe outra série no mundo que mexa comig...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tá foda de desviar de todos os spoilers de la ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>todoroki_jun né tô me sentindo em lá casa de p...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la casa de papel é tão ruim que nem consegui t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>em respeito ao meu casal fav de la casa de pap...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>assistindo la casa de papel para poder falar m...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>sexo não kk veste a roupa aí que a gente vai m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>meu deus o final de la casa de papel…………</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>sexo rosto_com_sobrancelha_levantada naokkkkk ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  \\\n",
       "0    quero terminar de ver a nova parte de la casa ...   \n",
       "1    não existe outra série no mundo que mexa comig...   \n",
       "2    tá foda de desviar de todos os spoilers de la ...   \n",
       "3    todoroki_jun né tô me sentindo em lá casa de p...   \n",
       "4    la casa de papel é tão ruim que nem consegui t...   \n",
       "..                                                 ...   \n",
       "195  em respeito ao meu casal fav de la casa de pap...   \n",
       "196  assistindo la casa de papel para poder falar m...   \n",
       "197  sexo não kk veste a roupa aí que a gente vai m...   \n",
       "198           meu deus o final de la casa de papel…………   \n",
       "199  sexo rosto_com_sobrancelha_levantada naokkkkk ...   \n",
       "\n",
       "     Classificação (relevante = 1, não relevante = 0)  \\\n",
       "0                                                   0   \n",
       "1                                                   1   \n",
       "2                                                   1   \n",
       "3                                                   0   \n",
       "4                                                   1   \n",
       "..                                                ...   \n",
       "195                                                 0   \n",
       "196                                                 0   \n",
       "197                                                 0   \n",
       "198                                                 1   \n",
       "199                                                 0   \n",
       "\n",
       "     Classificacao_Naive_Bayes  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            1  \n",
       "4                            0  \n",
       "..                         ...  \n",
       "195                          1  \n",
       "196                          1  \n",
       "197                          0  \n",
       "198                          1  \n",
       "199                          0  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Teste'] = test['Teste'].apply(limpeza_e_emoji)\n",
    "test['Classificacao_Naive_Bayes'] = test['Teste'].apply(Classificacao)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo foi de:  68.5 %\n"
     ]
    }
   ],
   "source": [
    "tp=test.loc[(test['Classificacao_Naive_Bayes']==1)&(test['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\n",
    "tn=test.loc[(test['Classificacao_Naive_Bayes']==0)&(test['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\n",
    "print('A acurácia do modelo foi de: ',100*(tp+tn)/test.shape[0],'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8480431bb365df6bcb1c44b7387c7b698c6b108659e761b6ab654603c809c5e"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
