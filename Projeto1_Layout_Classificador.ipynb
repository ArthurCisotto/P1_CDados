{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Arthur Cisotto Machado\n",
    "\n",
    "Nome: Alessandra Yumi Carvalho Ogawa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONTEXTO DO PROJETO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A empresa de streaming *Netflix* em parceria com o estúdio espanhol *Vancouver Media* deseja saber e analisar como a audiencia está reagindo a série de sucesso *La Casa de Papel* na rede social Twitter. \r\n",
    "O projeto exige a criação de um programa que consiga classificar os tweets entre **relevantes** ou **irrelevantes** para a análise da empresa.\r\n",
    "\r\n",
    "A classificação foi feita com o intúito de ajudar a área de marketing das duas empresas parceiras a acharem comentários que possam ser úteis em algum sentido estratégio para mudança de operações internas e também como fonte de *feedback* em relação ao conteúdo cinematográfico produzido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\r\n",
    "#### CARREGANDO AS BIBLIOTECAS UTILIZADAS NO PROGRAMA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /Users/alessandrayumiogawa/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alessandrayumiogawa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alessandrayumiogawa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import re \r\n",
    "import emoji\r\n",
    "from emoji import UNICODE_EMOJI\r\n",
    "import nltk \r\n",
    "from nltk.stem import RSLPStemmer\r\n",
    "nltk.download('rslp')\r\n",
    "nltk.download('punkt')\r\n",
    "nltk.download('stopwords')\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "/Users/alessandrayumiogawa/Documents/INSPER/INSPER - 2A/C-DADOS/P1_CDados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\r\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\r\n",
    "#### FUNÇÃO DE LIMPEZA DOS TWEETS:\r\n",
    "- tira sinais de pontuação irrelevantes para o texto;\r\n",
    "- todas as fontes são convertidas para letras minúsculas para evitar diferenciação pelo classificador;\r\n",
    "- exclui repetição de emoji;\r\n",
    "- substitui emoji por seu código;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "\n",
    "    punctuation = '[”/-@\\\\n:;?\\\"\\'().,]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    text_split = text_subbed.split()\n",
    "    return ' '.join(text_split).lower()\n",
    "\n",
    "def limpa_emoji(tweet): #função para \"limpar\" os emojis do tweet\n",
    "    tweet_com_emojis_separados=' '.join(emoji.get_emoji_regexp().split(tweet)) \n",
    "    #juntando o tweet em uma string só\n",
    "    #a função separa os emojis seguidos um do outro\n",
    "    #split para separar as palavras e cada emoji dentro do tweet\n",
    "    tweet_filtrado = '' #nova variável para armazenar o tweet limpo\n",
    "    for palavra in tweet_com_emojis_separados.split(): #inicializa o loop que percorre a lista de palavras e emojis separados no tweet\n",
    "        if palavra in UNICODE_EMOJI['pt']: #se a palavra estiver na biblioteca de códgos em portugues...\n",
    "            tweet_filtrado += UNICODE_EMOJI['pt'][palavra].replace(':','') #o emoji será trocado pelo código escrito do emoji\n",
    "            #como o código vem no modelo :CÓDIGO_DO_EMOJI: trocamos : por '' espaço vazio para depois compor a palavra de volta\n",
    "            tweet_filtrado += ' ' #adiciona espaço para a frase ser composta com os espaços corretamente após cada palavra\n",
    "        elif palavra in UNICODE_EMOJI['en']: #se a palavra estiver na biblioteca de códgos em inglês... (mesmo processo que o anterior)\n",
    "            tweet_filtrado += UNICODE_EMOJI['en'][palavra].replace(':','')\n",
    "            tweet_filtrado += ' '\n",
    "        else: #se nao estiver nessas bibliotecas provavelmente o o emoji será uma palavra (string) normal (resto do processo de recomposição da da frase)\n",
    "            tweet_filtrado += palavra\n",
    "            tweet_filtrado += ' '\n",
    "    return tweet_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTRAS FUNÇÕES DE LIMPEZA \r\n",
    "Como proposta de outras limpezas/transformações que não afetem a qualidade da informação decidimos fazer a limpeza de stopwords, isso é, a remoção de palavras como preposições, pronomes, artigos e verbos de estado que não afetam a qualidade do conteúdo geral dos tweets, e o stemming das palavras, isso é, diminuir as palavras até seu radical para que o classificador consiga tratar as palavras e suas  derivações da mesma maneira. Por exemplo: as palavras casa, casinha e casebre serão reduzidas ao seu radical 'cas'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Função que remove palavras comuns que não afetam a qualidade da informação contida, como preposições, pronomes, artigos e verbos de estado.\r\n",
    "def remove_stopwords(lista_palavras):\r\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\r\n",
    "    frase = []\r\n",
    "    for palavra in lista_palavras:\r\n",
    "        if palavra not in stopwords:\r\n",
    "            frase.append(palavra)\r\n",
    "    return frase\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "##Todas as palavras consideradas como stopwords pela biblioteca usada:\r\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\r\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "##A função RSLPStemmer significa Removedor de Sufixos da Lingua Portuguesa, ela reduz as palavras até seu radical\r\n",
    "def radicais(lista_palavras):\r\n",
    "    stemmer = RSLPStemmer()\r\n",
    "    frase = []\r\n",
    "    for palavra in lista_palavras:\r\n",
    "        frase.append(stemmer.stem(palavra))\r\n",
    "    return frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilado das funções de limpeza em uma só para mais fácil aplicação\r\n",
    "def limpeza_total(tweet):\r\n",
    "    texto_sem_pontuacoes = cleanup(tweet)\r\n",
    "    sem_emoji = limpa_emoji(texto_sem_pontuacoes)\r\n",
    "    lista_tweet = sem_emoji.split()\r\n",
    "    lista_tweet_sem_stopwords = remove_stopwords(lista_tweet)\r\n",
    "    lista_tweet_com_stemming = radicais(lista_tweet_sem_stopwords)\r\n",
    "    tweet_limpo = ' '.join(lista_tweet_com_stemming)\r\n",
    "    return tweet_limpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### CARREGANDO A BASE DE DADOS COM OS TWEETS CLASSIFICADOS COMO ***RELEVANTES*** E ***IRRELEVANTES*** MANUALMENTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'la casa de papel.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação do documento em dois DataFrames diferentes: **Treinamento** e **Teste**.\n",
    "\n",
    "- **Treinamento**: composto por 300 tweets classificados manualmente, será usado para *ensinar* o programa a classificar um tweets de acorodo com a sua relevância levando em conta as palavras em seu conteúdo.\n",
    "\n",
    "- **Teste**: composto por 200 tweets classificados manualmente, será usado para *testar* o programa classificador e comparar o resultado com a classificação feita à mão anteriormente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Treinamento</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tô vend la cas papel mdsss prim ep tir fôleg</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>agor vou assist lá cas papel dorm porq amanhã ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ded coç pra assist lá cas papel esper rosto_ex...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>la cas papel faz torc pro band</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la cas papel acab comig encontr desidrat tant ...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                         Treinamento  \\\n0       tô vend la cas papel mdsss prim ep tir fôleg   \n1  agor vou assist lá cas papel dorm porq amanhã ...   \n2  ded coç pra assist lá cas papel esper rosto_ex...   \n3                     la cas papel faz torc pro band   \n4  la cas papel acab comig encontr desidrat tant ...   \n\n   Classificação (relevante = 1, não relevante = 0)  \n0                                               1.0  \n1                                               0.0  \n2                                               0.0  \n3                                               1.0  \n4                                               1.0  "
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\r\n",
    "train['Treinamento'] = train['Treinamento'].apply(limpeza_total) #aplicando a função de limpeza\r\n",
    "train.head(5)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Teste</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>quer termin ver nov part la cas papel má to tã...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>exist outr séri mund mex comig la cas papel pqp</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tá fod desvi tod spoil la cas papel</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>todoroki_jun né tô sent lá cas papel</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la cas papel tão ruim consegu termin so t t q ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                               Teste  \\\n0  quer termin ver nov part la cas papel má to tã...   \n1    exist outr séri mund mex comig la cas papel pqp   \n2                tá fod desvi tod spoil la cas papel   \n3               todoroki_jun né tô sent lá cas papel   \n4  la cas papel tão ruim consegu termin so t t q ...   \n\n   Classificação (relevante = 1, não relevante = 0)  \n0                                                 0  \n1                                                 1  \n2                                                 1  \n3                                                 0  \n4                                                 1  "
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "test['Teste'] = test['Teste'].apply(limpeza_total)\r\n",
    "test.head(5)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS**: a função de limpeza já foi aplicada no DataFrame de treinamento e  teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### CLASSIFICADOR AUTOMÁTICO DE SENTIMENTO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O filtro criado para a realização da classificação manual seguia o padrão especificado abaixo:\n",
    "\n",
    "**RELEVANTES**: As mensagens de texto com relevância mostravam a opinião e sentimentos, sejam eles positivos ou negativos, sobre a série.\n",
    "*Consideramos tweets relacionados a spoilers como relevantes pois eles também demonstram um forte sentimento que as pessoas possuem em relação à série.\n",
    "\n",
    "**IRRELEVANTES**: Classificamos como não relevantes tweets que não se encaixaram na nossa classificação de relevância, tweets que falavam sobre tópicos pessoais ou tweets que falavam sobre algum personagem específico da série.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### MONTANDO UM CLASSIFICADOR NAÏVE-BAYES:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PREPARANDO OS DADOS DO TREINAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando filtros para separar os tweets relevantes dos irrelevantes\r\n",
    "\r\n",
    "filtro_nao_relevante = train['Classificação (relevante = 1, não relevante = 0)']==0\r\n",
    "filtro_relevante = train['Classificação (relevante = 1, não relevante = 0)']==1\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando em dois DFs diferentes os tweets relevantes e irrelevantes\r\n",
    "\r\n",
    "relevantes_train = train[filtro_relevante]\r\n",
    "nao_relevantes_train = train[filtro_nao_relevante]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando uma string grande para armazenar todos os tweets de cada classificação\r\n",
    "\r\n",
    "relevantes_train_txt = ''\r\n",
    "for tweet in relevantes_train['Treinamento']:\r\n",
    "    relevantes_train_txt += \" \"\r\n",
    "    relevantes_train_txt += str(tweet)\r\n",
    "\r\n",
    "nao_relevantes_train_txt = ''\r\n",
    "for tweet in nao_relevantes_train['Treinamento']:\r\n",
    "    nao_relevantes_train_txt += \" \"\r\n",
    "    nao_relevantes_train_txt += str(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organizando os tweets em listas de palavras e pandas Series \r\n",
    "\r\n",
    "#fazendo a lista com todas as palavaras dos tweets\r\n",
    "todas_palavras_relevantes = relevantes_train_txt.split()\r\n",
    "todas_palavras_irrelevantes = nao_relevantes_train_txt.split()\r\n",
    "\r\n",
    "#transformando a lista em uma panda Series\r\n",
    "serie_relevante = pd.Series(todas_palavras_relevantes)\r\n",
    "serie_irrelevante = pd.Series(todas_palavras_irrelevantes)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PREPARANDO AS TABELAS DE FREQUÊNCIA ABSOLUTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relevante = serie_relevante.value_counts()\r\n",
    "tabela_irrelevante = serie_irrelevante.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que o conjunto universo seja apenas a soma de todas as palavras em tweets relevantes e irrelevantes na base de treinamento, a seguir cria-se esse conjunto somando as strings de ambas. \r\n",
    "\r\n",
    "Além disso prosseguiu-se com o tratamento de dados criando uma lista com todas essas palavras e depois um pandas Series onde pode-se realizar a contagem da frequência de cada palavra e a partir daí começar o treinamento do programa partindo do conjunto universo de palavras.\r\n",
    "\r\n",
    "Para finalizar o tratamento do conjunto universo de palavras, cria-se uma lista de palavras excluindo as repetidas que serão usadas depois no método de ***Suavização de Laplace***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organizando o conjunto universo de todas as palavras\r\n",
    "\r\n",
    "palavras = relevantes_train_txt + nao_relevantes_train_txt\r\n",
    "todas_palavras = palavras.split()\r\n",
    "serie_palavras = pd.Series(todas_palavras)\r\n",
    "tabela_palavras = serie_palavras.value_counts(normalize=True)\r\n",
    "\r\n",
    "\r\n",
    "palavras_sem_repeticao = []\r\n",
    "for e in todas_palavras:\r\n",
    "    if e not in palavras_sem_repeticao:\r\n",
    "        palavras_sem_repeticao.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MONTANDO AS PROBABILIDADES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definindo os eventos:\n",
    "\n",
    "- $P(tweet|R)$: probabilidade de o tweet ser classificado como relevante;\n",
    "- $P(tweet|IR)$: probabilidade de o tweet ser classificado como irrelevante;\n",
    "- $P(R)$: probabilidade de um tweet ser relevante;\n",
    "- $P(IR)$: probabilidade de um tweet ser irrelevante;\n",
    "\n",
    "$$\\quad P(R) = \\frac{N palavras RELEVANTES}{N total palavras}$$  \n",
    "$$\\quad P(IR) = \\frac{N palavras IRRELEVANTES}{N total palavras}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculando a probabilidade de um tweet ser relevante ou irrelevante\r\n",
    "probR = len(serie_relevante)/len(serie_palavras)\r\n",
    "probIR = len(serie_irrelevante)/len(serie_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aplicação do Teorema de Bayes:\n",
    "\n",
    "Apresentação do teorema:\n",
    "$\\quad P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$  \n",
    "  \n",
    "Que nesse contexto seria equivalente à:  \n",
    "  \n",
    "$$\\quad P(R|tweet) = \\frac{P(tweet|R)P(R)}{P(tweet)}$$  \n",
    "$$\\quad P(IR|tweet) = \\frac{P(tweet|IR)P(IR)}{P(tweet)}$$  \n",
    "  \n",
    "É necessário realizar o cálculo de $P(tweet|R)$ e $P(tweet|IR)$ para aplicar o teorema e desse modo calcular a probbilidade de o tweet ser classificado como **relevante** ou **irrelevante**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRIMEIRA FUNÇÃO: calculando a probabilidade de uma X aparecer dado um dos conjuntos (relevante ou irrelevante)\r\n",
    "\r\n",
    "def probDadoconj(palavra, prob_conj, lista_palavras_conj):\r\n",
    "    if palavra in lista_palavras_conj:\r\n",
    "        return prob_conj[palavra]\r\n",
    "    else:\r\n",
    "        return 0\r\n",
    "\r\n",
    "#exemplo: print(probDadoconj(\"la\", tabela_relevante, todas_palavras_relevantes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suavização de Laplace (\"Laplace Soothing\"):\r\n",
    "\r\n",
    "Essa técnica é utilizada para evitar que uma probabilidade seja ZERO caso o Teorema de Bayes seja aplicado à uma amostra fora da base de dados que compõe o conjunto universo do que está sendo considerado como a totalidade de palavras em tweets.  \r\n",
    "\r\n",
    "A possibilidade de resultar em zero vem do cálculo da probabilidade de um tweet ser classificado como relevante ou irrelevante já que é efetuada a multiplicação entre as probabilidades de cada palavra ser um indicador de relevância ou irrelevância.  \r\n",
    "\r\n",
    "Aplicando a suavização:\r\n",
    "$$\\quad P(palavra|conjunto) = \\frac{P(palavra|conjunto)+1}{palavras  conjunto + palavras sem repetição}$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEGUNDA FUNÇÃO: aplicando a suavização de Laplace\r\n",
    "\r\n",
    "def aplicando_laplace(prob_dado_conj, lista_palavras_conj):\r\n",
    "    return (prob_dado_conj+1)/(len(lista_palavras_conj)+len(palavras_sem_repeticao))\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CLASSIFICAÇÃO FINAL: \n",
    "\n",
    "Para realizar a classificação compila-se ambas as funções em uma só para que seja mais fácil de aplicar para todo o documento de tweets na base de treino.  \n",
    "\n",
    "Nela é calculada a probabilidade de um tweet ser classificado como relevante e como irrelevante e no fim é feita uma comparação retornando a classificação com maior probabilidade de ocorrer:  \n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(R|tweet) > P(IR|tweet)$, então o tweet será classificado como de **relevante**.\n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(IR|tweet) > P(R|tweet)$, então o tweet será classificado como de **irrelevante**.\n",
    "\n",
    "**Lembrando que**: a probabilidade é construída multiplicando a probabilidade de cada palavra na frase do tweet estar presente em relevância ou irrelevância:  \n",
    "\n",
    "$\\quad P(tweet|conj) = \n",
    "P(palavra1|conj)\\cdot P(palavra2|conj)\\cdot P(palavra3|conj)\\cdot P(palavra4|conj)\\cdot...$  \n",
    "\n",
    "E portanto a fórmula ficará:  \n",
    "\n",
    "$P(conj|tweet) = P(palavra1|conj)\\cdot P(palavra2|conj)\\cdot P(palavra3|conj)\\cdot P(palavra4|conj)\\cdot... P(conj)$  \n",
    "Vale ressaltar que a divisão por $P(tweet)$ não é necessária na hora de fazer a comparação uma vez que em ambas a probabilidades isso seria feito, então podemos tratá-lo como um fator comum no cálculo e desconsiderar a divisão por simplificação da fórmula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNÇÃO FINAL: compilado das duas funções anteriores\r\n",
    "#essa função realiza duas vezes as funções escritas anteriormente e depois comparam seus resultados para classificar\r\n",
    "\r\n",
    "def Classificacao(tweet):\r\n",
    "    prob_relevante = 1\r\n",
    "    lista_tweet = tweet.split()\r\n",
    "    for palavra in lista_tweet:\r\n",
    "        prob = probDadoconj(palavra, tabela_relevante, todas_palavras_relevantes)\r\n",
    "        prob_laplace = aplicando_laplace(prob, todas_palavras_relevantes)\r\n",
    "        prob_relevante *= prob_laplace\r\n",
    "    probRtweet = prob_relevante*probR\r\n",
    "    prob_irrelevante = 1\r\n",
    "    for palavra in lista_tweet:\r\n",
    "        prob = probDadoconj(palavra, tabela_irrelevante, todas_palavras_irrelevantes)\r\n",
    "        prob_laplace = aplicando_laplace(prob, todas_palavras_irrelevantes)\r\n",
    "        prob_irrelevante *= prob_laplace\r\n",
    "    probIRtweet = prob_irrelevante*probIR\r\n",
    "    if probRtweet < probIRtweet: \r\n",
    "        return 0 #Irrelevante\r\n",
    "    else: \r\n",
    "        return 1 #Relevante\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando a função na base de treinamento (PRIEMIRO TESTE): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Treinamento</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n      <th>Classificacao_Naive_Bayes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tô vend la cas papel mdsss prim ep tir fôleg</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>agor vou assist lá cas papel dorm porq amanhã ...</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ded coç pra assist lá cas papel esper rosto_ex...</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>la cas papel faz torc pro band</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la cas papel acab comig encontr desidrat tant ...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>tô aqu assist la cas papel ler tod spoil cabeç...</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>ach nenhum mort la cas papel ia super nairob r...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>caralh to chor igual vagabund porr la cas papel</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>car nunc chor tant quant chor olh final lá cas...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>caralh la cas papel</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 3 columns</p>\n</div>",
      "text/plain": "                                           Treinamento  \\\n0         tô vend la cas papel mdsss prim ep tir fôleg   \n1    agor vou assist lá cas papel dorm porq amanhã ...   \n2    ded coç pra assist lá cas papel esper rosto_ex...   \n3                       la cas papel faz torc pro band   \n4    la cas papel acab comig encontr desidrat tant ...   \n..                                                 ...   \n295  tô aqu assist la cas papel ler tod spoil cabeç...   \n296  ach nenhum mort la cas papel ia super nairob r...   \n297    caralh to chor igual vagabund porr la cas papel   \n298  car nunc chor tant quant chor olh final lá cas...   \n299                                caralh la cas papel   \n\n     Classificação (relevante = 1, não relevante = 0)  \\\n0                                                 1.0   \n1                                                 0.0   \n2                                                 0.0   \n3                                                 1.0   \n4                                                 1.0   \n..                                                ...   \n295                                               0.0   \n296                                               1.0   \n297                                               1.0   \n298                                               1.0   \n299                                               1.0   \n\n     Classificacao_Naive_Bayes  \n0                            1  \n1                            0  \n2                            0  \n3                            1  \n4                            1  \n..                         ...  \n295                          0  \n296                          1  \n297                          1  \n298                          1  \n299                          1  \n\n[300 rows x 3 columns]"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Classificacao_Naive_Bayes'] = train.Treinamento.apply(Classificacao)\r\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia na base de treinamento foi de: 94.33333333333334%\n"
     ]
    }
   ],
   "source": [
    "#Porcentagem de acerto no conjunto de Treino:\r\n",
    "\r\n",
    "verdadeiros_positivos_train=train.loc[(train['Classificacao_Naive_Bayes']==1)&(train['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "verdadeiros_negativos_train=train.loc[(train['Classificacao_Naive_Bayes']==0)&(train['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "print(f'A acurácia na base de treinamento foi de: {((verdadeiros_positivos_train+verdadeiros_negativos_train)/train.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### BASE DE TESTE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VERIFICANDO A PERFORMANCE DO CLASSIFICADOR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Teste</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n      <th>Classificacao_Naive_Bayes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>quer termin ver nov part la cas papel má to tã...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>exist outr séri mund mex comig la cas papel pqp</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tá fod desvi tod spoil la cas papel</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>todoroki_jun né tô sent lá cas papel</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la cas papel tão ruim consegu termin so t t q ...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                               Teste  \\\n0  quer termin ver nov part la cas papel má to tã...   \n1    exist outr séri mund mex comig la cas papel pqp   \n2                tá fod desvi tod spoil la cas papel   \n3               todoroki_jun né tô sent lá cas papel   \n4  la cas papel tão ruim consegu termin so t t q ...   \n\n   Classificação (relevante = 1, não relevante = 0)  Classificacao_Naive_Bayes  \n0                                                 0                          0  \n1                                                 1                          1  \n2                                                 1                          1  \n3                                                 0                          1  \n4                                                 1                          0  "
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Classificacao_Naive_Bayes'] = test['Teste'].apply(Classificacao)\r\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DESCRIÇÃO DA PERFORMANCE DO CLASSIFICADOR:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As contagens a seguir são feitas comparando os valores da coluna em que fizemos a classificação manualmente *\"Classificação (relevante = 1, não relevante = 0)\"* com os valores da coluna em que a classificação foi feita de maneira automática pela função criada anteriormente para nosso classificador *\"Classificacao_Naive_Bayes\"*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Porcentagem de verdadeiros positivos (mensagens relevantes e que são classificadas como relevantes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de verdadeiros positivos na base de teste foi de: 51.0%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_positivos=test.loc[(test['Classificacao_Naive_Bayes']==1)&(test['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "print(f'A porcentagem de verdadeiros positivos na base de teste foi de: {(verdadeiros_positivos/test.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Porcentagem de falsos positivos (mensagens irrelevantes e que são classificadas como relevantes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de falsos positivos na base de teste foi de: 23.5%\n"
     ]
    }
   ],
   "source": [
    "falsos_positivos=test.loc[(test['Classificacao_Naive_Bayes']==1)&(test['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "print(f'A porcentagem de falsos positivos na base de teste foi de: {(falsos_positivos/test.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Porcentagem de verdadeiros negativos (mensagens irrelevantes e que são classificadas como irrelevantes):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de verdadeiros negativos na base de teste foi de: 18.5%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_negativos=test.loc[(test['Classificacao_Naive_Bayes']==0)&(test['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "print(f'A porcentagem de verdadeiros negativos na base de teste foi de: {(verdadeiros_negativos/test.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Porcentagem de falsos negativos (mensagens relevantes e que são classificadas como irrelevantes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de falsos negativos na base de teste foi de: 7.000000000000001%\n"
     ]
    }
   ],
   "source": [
    "falsos_negativos=test.loc[(test['Classificacao_Naive_Bayes']==0)&(test['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "print(f'A porcentagem de falsos negativos na base de teste foi de: {(falsos_negativos/test.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Acurácia (mensagens corretamente classificadas, independente da categoria):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia na base de teste foi de: 69.5%\n"
     ]
    }
   ],
   "source": [
    "print(f'A acurácia na base de teste foi de: {((verdadeiros_positivos+verdadeiros_negativos)/test.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### CONCLUINDO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparativo qualitativo sobre os percentuais obtidos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador obteve uma performance boa de ***69,50%*** de acerto. A seguir apresentam-se comentário a respeito dos erros e acertos do classificador:\n",
    "\n",
    "**Verdadeiros positivos:** A maior porcentagem de performances verdadeiras veio das classificações relevantes. Isso pode ser explicado pelo tamanho da base de dados utilizada para tweets relevantes. Na classificação manual houve discrepância entre a percentagem de tweets relevantes para irrelevantes, o que faz com que o classificador de certo modo tenha uma \"especialidade\" melhor na classificação relevante - já que ela possui maior repertório com palavras que indicam relevância em tweets. ***(51.0%)***\n",
    "\n",
    "**Falsos positivos:** A maior porcentagem de performances falsas veio das classificações relevantes falsamente. Essa porcentagem pode ser explicada também pelo fato de ter-se a base de dados dos tweets \"enviesadas\" à palavras que indicam relevância. Além disso, como mencionado anteriormente, o classificador não entende propriamente dito a língua portuguesa; apenas relaciona as palavras que cada tweet possui com a base de dados classificada manualmente, fazendo com que os textos irônicos ou que possui alguma especifidade da línguagem coloquia sejam classificados de forma errônea dependendo do contexto. ***(23.5%)***\n",
    "\n",
    "**Verdadeiros negativos:** Os acertos em relação à classificação de tweets irrelevantes é baixo, apesar disso esse número pode representar uma falsa conclusão sobre a performance do classificador. Por possuir menos tweets classificados como irrelevantes, por si só a porcentagem de irrelevantes na base de treino é pequena. Apesar disso, a pequena porcentagem também pode explicada pela base de dados carente em variedade de palavras indicadoras de irrelevância como mencionado anteriormente. ***(18.5%)***\n",
    "\n",
    "**Falsos negativos:** Os erros em relação a classificação irrelevantes são pequenos, podendo ser explicado também pela base de treinamento e teste decadentes em relação à variação de tweets irrelevantes. Sem grandes variações, os tweets irrelevantes apresentam um padrão concentrado e \"padronizado\", que faz com que a quantidade de erros nessa categoria seja pequena. Apesar disso, isso também representa um problema como mencionado antes, já que variações na forma de irrelevância serão dificilmente detectadas pelo classificador por causa da carência de repertório \"irrelevante\". ***(7.000000000000001%)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mensagens com dupla negação e sarcasmo e a ingenuidade do Naïve Bayes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O programa Naïve Bayes pode ser caracterizado como um sitema ingênuo, uma vez que dentro do cálculo das probabilidades ele considera que cada palavra dentro dos tweets são independentes entre si, e que suas probabilidades de aparição independem completamente dos elementos que a antecedem ou a seguem. Isso porque o programa não conhece a língua portuguesa ou qualquer outra língua falada; a gramática e regras de escrita/fala não são conhecidsa pelo algorítmo, tudo que ele tem é um universo reduzido de palavras na língua portuguesa providos da base de 500 tweets selecionados no começo do projeto. Isso ajuda a explicar a falha que o programa apresenta ao se deparar com textos sarcásticos ou com outras figuras de linguagem.\r\n",
    "\r\n",
    "Tanto o sarcasmo quanto a dupla negação são elementos de linguagem que vêm do uso cotidiano e \"relaxado\" da língua. Não existe nenhuma regra formal concretizada que defina um padrão no uso de nenhuma delas.  \r\n",
    "\r\n",
    "Com isso dito começa a ficar claro como o programa reage à tweets sarcasticos ou que contém dupla negação. Como ele não conhece as características específicas da linguagem, o programa vai tratar a frase com o sentido **literal**, que muitas vezes é o oposto do que o sarcasmo ou a dupla negação querem dizer.  \r\n",
    "\r\n",
    "Por isso pode-se dizer que o programa pode ser falho na hora de classificar tweets desse gênero, dada sua incapacidade de compreender as especificidades da língua portuguesa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependência da classificação manual para alimentação da base de dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como abordado anteriormente, o programa desconhece as especificidades das línguas, muitas vezes falhando em classificar corretamente expressões de linguagem, ditados populares ou figuras de linguagem.  \r\n",
    "\r\n",
    "Isso impossibilita que a classificação automática de novos tweets para a base de dados seja feita uma vez que a classificação errônea desses casos criaria uma incerteza e inconsistência na classificação dos demais que com o tempo seria propagada contribuido negativamente para a maior acurácia e eficácia do programa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plano de expansão:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A empresa de streaming *Netflix* e o estúdio espanhol *Vancouver Media* devem continuar financiando o nosso projeto pois a partir da análise de dados feita com o nosso classificador e o *feedback* obtido em relação ao conteúdo cinematográfico produzido a partir dela, as empresas poderiam planejar uma próxima temporada ou uma nova série com maior conhecimento sobre o que o público alvo gosta e não gosta. Desse modo, os recursos de uma nova produção poderiam ser alocados de maneira mais estratégica para atingir uma maior satisfação do público. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diferentes cenários de uso para o classificador Naive-Bayes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alguns exemplos de aplicações para um classificador Naive-Bayes são:\r\n",
    "- Serviços como o Gmail podem marcar um email como spam ou não automaticamente\r\n",
    "- Prever se em um determinado dia vai chover ou não baseado em medições de temperatura, umidade, pressão, etc.\r\n",
    "- Um banco poderia prever o risco de crédito de um cliente baseado em diversos dados para decidir aprovar ou não um empréstimo\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possíveis melhorias no classificador e como implementá-las:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ainda mais limpezas na base de dados:  \r\n",
    "    Além da limpeza de stopwords e stemming, poderíamos propor outras limpezas/transformações que não afetem a qualidade da informação.  \r\n",
    "    Alguns exemplos:  \r\n",
    "    - Lemmatization:  \r\n",
    "    Ao contrário do Stemming, que funciona cortando o final da palavra, levando em conta uma lista de sufixos comuns que podem ser encontrados em uma palavra flexionada, o processo de Lemmatization leva em consideração a análise morfológica das palavras. Para isso, é necessário ter dicionários detalhados que o algoritmo possa examinar para ligar a palavra de volta a seu 'lemma'. \r\n",
    "    Por exemplo: enquanto a palavra \"estudando\" no stemming seria reduzida a 'estud', no lemmatization ela seria ligada a base 'estudo'.  \r\n",
    "    Poderíamos implementar lemmatization com o uso de bibliotecas externas. O Natural Language Toolkit, ou NLTK, é um conjunto famoso de bibliotecas para processamento de linguagem natural para inglês, usamos funções dele para implementar a limpeza de stopwords e o stemming, mas ele não possuí nenhum lemmatizer para a língua portuguesa.  \r\n",
    "    Ao pesquisar por \"lemmatization python portugues\", encontramos um post em um blog apresentando diversas opções de lemmatizers para a língua portuguesa: [Portuguese Lemmatizers (2020 update)](https://lars76.github.io/2018/05/08/portuguese-lemmatizers.html), dentre essas opções a biblioteca 'Universal Lemmatizer' parece ser a mais adequada pois ela possui variações específicas para o português brasileiro. Ao implementar as funções dessa biblioteca nos tweets, teríamos o texto com cada palavra reduzida ao seu 'lemma' e, então, o classificador conseguiria tratar as palavras e suas derivações da mesma maneira.  \r\n",
    "  \r\n",
    "- N-grams:  \r\n",
    "Ao invés de contarmos palavras isoladas como fizemos no nosso classificador, podíamos contar sequências de palavras, como \"la casa de papel\" em vez de \"la\", \"casa\", \"de\" e \"papel\".  \r\n",
    "Poderíamos implementar o método de n-grams a partir de uma função (ngrams) do Natural Language Toolkit, ou NLTK, que mencionamos anteriormente. Encontramos um post em um blog apresentando como implementar a técnica de n-grams com o NTLK e também puramente com python sem o auxílio de bibliotecas externas: [Generating N-grams from Sentences in Python](https://albertauyeung.github.io/2018/06/03/generating-ngrams.html)\r\n",
    "- TF-IDF:  \r\n",
    "Em vez de apenas contar a frequência, poderíamos ponderar as palavras que aparecem com frequência na maioria dos textos. O método TF-IDF (term frequency-inverse document frequency) assume que a relevância de uma palavra é inversamente proporcional à frequência com que ela ocorre em todos os documentos.Ele é calculado pela multiplicação de quantas vezes uma palavra aparece em um documento com a frequência inversa da palavra em um conjunto de documentos. Poderíamos implementar o método de TF-IDF por meio de uma função chamada TfidfVectorizer (sklearn.feature_extraction.text.TfidfVectorizer) da biblioteca scikit-learn, muito utilizada em Python para trabalhar com Machine Learning. Podemos encontrar mais detalhes sobre o funcionamento dela em sua [documentação](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Encontramos também um [site](https://www.computersciencemaster.com.br/como-implementar-o-tf-idf-em-python/) que demonstra como implementar o TF-IDF apenas com o uso do NTLK.\r\n",
    "\r\n",
    "Outros materiais de estudo consultados:\r\n",
    "- [A practical explanation of a Naive Bayes classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/)\r\n",
    "- [Naive Bayes and Text Classification](https://sebastianraschka.com/Articles/2014_naive_bayes_1.html#n-grams)\r\n",
    "- [What is the difference between stemming and lemmatization?](https://blog.bitext.com/what-is-the-difference-between-stemming-and-lemmatization/)\r\n",
    "- [Understanding TF-IDF: A Simple Introduction](https://monkeylearn.com/blog/what-is-tf-idf/)\r\n",
    "- [Classificação de Textos em Python](https://www.linkedin.com/pulse/classificação-de-textos-em-python-luiz-felipe-araujo-nunes/?originalSubdomain=pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\r\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\r\n",
    "\r\n",
    "Para fazer esse item do Projeto, utilizamos a biblioteca scikit-learn (sklearn) que contém diversas funções úteis para a análise preditiva de dados. Em especial, utilizaremos a função train_test_split que divide listas e séries de dados em bases de treinamento e teste aleatoriamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder usar a função para dividir nossa base inteira em novas bases de treinamento e teste, primeiramente vamos unir as duas bases em uma única série a partir da função 'concat' do Pandas.  \r\n",
    "  \r\n",
    "Para que todos os tweets fiquem em um uma única coluna para que eles possam ser divididos novamente, precisamos renomear a coluna que descrevia se ele fazia parte do teste ou treinamento para um nome unificado 'Tweets'.  \r\n",
    "  \r\n",
    "Ademais, precisamos remover a coluna de classificação feita pelo nosso classificador ('Classificacao_Naive_Bayes'), para que ela possa ser feita novamente em cada uma das repetições do processo com base na nova base de treinamento.  \r\n",
    "  \r\n",
    "*Note que não precisamos aplicar as funções de limpeza novamente nas bases pois a base total de tweets já está sendo criada com as séries previamente limpas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tô vend la cas papel mdsss prim ep tir fôleg</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>agor vou assist lá cas papel dorm porq amanhã ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ded coç pra assist lá cas papel esper rosto_ex...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                              Tweets  \\\n0       tô vend la cas papel mdsss prim ep tir fôleg   \n1  agor vou assist lá cas papel dorm porq amanhã ...   \n2  ded coç pra assist lá cas papel esper rosto_ex...   \n\n   Classificação (relevante = 1, não relevante = 0)  \n0                                               1.0  \n1                                               0.0  \n2                                               0.0  "
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_para_concat = train\r\n",
    "train_para_concat = train_para_concat.rename(columns={\"Treinamento\": \"Tweets\"})\r\n",
    "train_para_concat =train_para_concat.drop(['Classificacao_Naive_Bayes'], axis=1)\r\n",
    "train_para_concat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>quer termin ver nov part la cas papel má to tã...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>exist outr séri mund mex comig la cas papel pqp</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tá fod desvi tod spoil la cas papel</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                              Tweets  \\\n0  quer termin ver nov part la cas papel má to tã...   \n1    exist outr séri mund mex comig la cas papel pqp   \n2                tá fod desvi tod spoil la cas papel   \n\n   Classificação (relevante = 1, não relevante = 0)  \n0                                                 0  \n1                                                 1  \n2                                                 1  "
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_para_concat = test\r\n",
    "test_para_concat = test_para_concat.rename(columns={\"Teste\": \"Tweets\"})\r\n",
    "test_para_concat =test_para_concat.drop(['Classificacao_Naive_Bayes'], axis=1)\r\n",
    "test_para_concat.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_inteira_tweets = pd.concat([train_para_concat, test_para_concat], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando a base inteira entre treinamento e teste 100 vezes e calculando a acurácia do classificador em cada uma das separações:\r\n",
    "  \r\n",
    "Em cada repetição do loop, a função train_test_split está sendo executada dividindo a base completa em novas bases de treinamento ('base_train') e teste ('base_test') mantendo a proporção de 200 tweets como teste (40%) e os outros 300 (60%) como treinamento, já que isso é especificado no parâmetro 'test_size' da função. O parâmetro 'random_state' com valor None garante que a cada vez que o loop repetir, uma nova divisão será feita, se ele recebesse um valor int específico a função faria a exata mesma divisão em todas as repetições do loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_acuracias = []\r\n",
    "for i in range(100):\r\n",
    "    #separando a base completa aleatoriamente entre train e test, mantendo a proporção de 200 tweets como teste (40%) e os outros 300 (60%) como treinamento\r\n",
    "    base_train, base_test = train_test_split(base_inteira_tweets, test_size=0.4, random_state=None)\r\n",
    "\r\n",
    "    #criando cópias dos próprios dataframes pra evitar o erro SettingWithCopyWarning\r\n",
    "    base_train = base_train.copy()\r\n",
    "    base_test = base_test.copy()\r\n",
    "\r\n",
    "    #criando filtros para separar os tweets relevantes dos irrelevantes\r\n",
    "    filtro_nao_relevante = base_train['Classificação (relevante = 1, não relevante = 0)']==0\r\n",
    "    filtro_relevante = base_train['Classificação (relevante = 1, não relevante = 0)']==1\r\n",
    "\r\n",
    "    #separando em dois DFs diferentes os tweets relevantes e irrelevantes\r\n",
    "    relevantes_train = base_train[filtro_relevante]\r\n",
    "    nao_relevantes_train = base_train[filtro_nao_relevante]\r\n",
    "\r\n",
    "\r\n",
    "    #criando uma string grande para armazenar todos os tweets de cada classificação\r\n",
    "    relevantes_train_txt = ''\r\n",
    "    for tweet in relevantes_train['Tweets']:\r\n",
    "        relevantes_train_txt += \" \"\r\n",
    "        relevantes_train_txt += str(tweet)\r\n",
    "    nao_relevantes_train_txt = ''\r\n",
    "    for tweet in nao_relevantes_train['Tweets']:\r\n",
    "        nao_relevantes_train_txt += \" \"\r\n",
    "        nao_relevantes_train_txt += str(tweet)\r\n",
    "    \r\n",
    "    #organizando os tweets em listas de palavras e pandas Series \r\n",
    "\r\n",
    "    #fazendo a lista com todas as palavaras dos tweets\r\n",
    "    todas_palavras_relevantes = relevantes_train_txt.split()\r\n",
    "    todas_palavras_irrelevantes = nao_relevantes_train_txt.split()\r\n",
    "\r\n",
    "    #transformando a lista em uma panda Series\r\n",
    "    serie_relevante = pd.Series(todas_palavras_relevantes)\r\n",
    "    serie_irrelevante = pd.Series(todas_palavras_irrelevantes)\r\n",
    "\r\n",
    "    tabela_relevante = serie_relevante.value_counts()\r\n",
    "    tabela_irrelevante = serie_irrelevante.value_counts()\r\n",
    "\r\n",
    "    #organizando o conjunto universo de todas as palavras\r\n",
    "\r\n",
    "    palavras = relevantes_train_txt + nao_relevantes_train_txt\r\n",
    "    todas_palavras = palavras.split()\r\n",
    "    serie_palavras = pd.Series(todas_palavras)\r\n",
    "    tabela_palavras = serie_palavras.value_counts(normalize=True)\r\n",
    "\r\n",
    "\r\n",
    "    palavras_sem_repeticao = []\r\n",
    "    for e in todas_palavras:\r\n",
    "        if e not in palavras_sem_repeticao:\r\n",
    "            palavras_sem_repeticao.append(e)\r\n",
    "    \r\n",
    "    #calculando a probabilidade de um tweet ser relevante ou irrelevante\r\n",
    "    probR = len(serie_relevante)/len(serie_palavras)\r\n",
    "    probIR = len(serie_irrelevante)/len(serie_palavras)\r\n",
    "\r\n",
    "    base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\r\n",
    "    verdadeiros_positivos=base_test.loc[(base_test['Classificacao_Naive_Bayes']==1)&(base_test['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "    verdadeiros_negativos=base_test.loc[(base_test['Classificacao_Naive_Bayes']==0)&(base_test['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "    acuracia = ((verdadeiros_positivos+verdadeiros_negativos)/base_test.shape[0])*100\r\n",
    "    lista_acuracias.append(acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "100"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Demonstrando que o processo foi repetido 100 vezes e, portanto, temos 100 contagens de acurácias\r\n",
    "len(lista_acuracias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'acurácia [em %]')"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 1440x1440 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 20))\r\n",
    "plt.hist(lista_acuracias, bins=10, edgecolor='white', color='crimson', density=True)\r\n",
    "plt.title('Histograma de acurácia do classificador em 100 simulações')\r\n",
    "plt.ylabel('densidade')\r\n",
    "plt.xlabel('acurácia [em %]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A respeito da criação de várias simulações de classificação de tweets entende-se que ela traz vantagens uma vez que testa-se várias vezes a acurácia do programa variando em partes a base de dados. O programa considera que as palavras que fazem parte de sua base de dados compõem o conjunto universo de palavras que podem criar texto, quando se alterna essa base é possível realizar o teste de acurácia levando em conta outras palavras que indicam **relevância** ou **irrelevância** para os tweets. \n",
    "\n",
    "Limitar-se à apenas um teste com uma base de dados pode apresentar uma crença falsa na acurácia do programa, já que ele aprasentará resultados baseados apenas em uma base que jamais poderá ser considerada como totalmente completa -  uma vez que palavras de 300 tweets não representam uma totalidade da língua portuguesa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96eb50e1d44aed467dc8f759cb08c32fbfa9babcf79c554e2d0e5feb04653a10"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}