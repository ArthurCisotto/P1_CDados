{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nome: Arthur Cisotto Machado\n",
    "\n",
    "Nome: Alessandra Yumi Carvalho Ogawa"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### CONTEXTO DO PROJETO "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A empresa de streaming *Netflix* em parceria com o estúdio espanhol *Vancouver Media* deseja saber e analisar como a audiencia está reagindo a série de sucesso *La Casa de Papel* na rede social Twitter. \n",
    "O projeto exige a criação de um programa que consiga classificar os tweets entre **relevantes** ou **irrelevantes** para a análise da empresa.\n",
    "\n",
    "A classificação foi feita com o intúito de ajudar a área de marketing das duas empresas parceiras a acharem comentários que possam ser úteis em algum sentido estratégio para mudança de operações internas e também como fonte de *feedback* em relação ao conteúdo cinematográfico produzido."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "#### CARREGANDO AS BIBLIOTECAS UTILIZADAS NO PROGRAMA:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%matplotlib inline\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import re \r\n",
    "import emoji\r\n",
    "from emoji import UNICODE_EMOJI\r\n",
    "import nltk \r\n",
    "from nltk.stem import RSLPStemmer\r\n",
    "nltk.download('punkt')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Arthur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print('Esperamos trabalhar no diretório')\r\n",
    "print(os.getcwd())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "c:\\Users\\Arthur\\Dropbox\\A - ARTHUR\\2o Semestre\\CDados\\P1_CDados\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\r\n",
    "#### FUNÇÃO DE LIMPEZA DOS TWEETS:\r\n",
    "- tira sinais de pontuação irrelevantes para o texto;\r\n",
    "- todas as fontes são convertidas para letras minúsculas;\r\n",
    "- exclui repetição de emoji;\r\n",
    "- substitui emoji por seu código;"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# https://docs.python.org/3/library/re.html#\r\n",
    "\r\n",
    "\r\n",
    "def cleanup(text):\r\n",
    "\r\n",
    "    punctuation = '[”/-@\\\\n:;?\\\"\\'().,]' \r\n",
    "    pattern = re.compile(punctuation)\r\n",
    "    text_subbed = re.sub(pattern, ' ', text)\r\n",
    "    text_split = text_subbed.split()\r\n",
    "    return ' '.join(text_split).lower()\r\n",
    "\r\n",
    "def limpa_emoji(tweet):\r\n",
    "    \r\n",
    "    modified=' '.join(emoji.get_emoji_regexp().split(tweet))\r\n",
    "    modified=modified.split()\r\n",
    "    for i,emoji1 in enumerate(modified):\r\n",
    "        if emoji1 in UNICODE_EMOJI['pt']:\r\n",
    "            modified[i]=UNICODE_EMOJI['pt'][emoji1].replace(':','')\r\n",
    "        elif emoji1 in UNICODE_EMOJI['en']:\r\n",
    "            modified[i]=UNICODE_EMOJI['en'][emoji1].replace(':','')\r\n",
    "        else:\r\n",
    "            continue\r\n",
    "    modified=' '.join(modified)\r\n",
    "        \r\n",
    "    return modified"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### OUTRAS FUNÇÕES DE LIMPEZA "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "##Função que remove palavras comuns que não afetam a qualidade da informação contida, como preposições, pronomes, artigos e verbos de estado.\r\n",
    "def remove_stopwords(lista_palavras):\r\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\r\n",
    "    frase = []\r\n",
    "    for palavra in lista_palavras:\r\n",
    "        if palavra not in stopwords:\r\n",
    "            frase.append(palavra)\r\n",
    "    return frase\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "##Todas as palavras consideradas como stopwords:\r\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\r\n",
    "print(stopwords)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def limpeza_total(tweet):                 #compilado das funções de limpeza em uma só para mais fácil aplicação\r\n",
    "    texto_sem_pontuacoes = cleanup(tweet)\r\n",
    "    sem_emoji = limpa_emoji(texto_sem_pontuacoes)\r\n",
    "    lista_tweet = sem_emoji.split()\r\n",
    "    lista_tweet_sem_stopwords = remove_stopwords(lista_tweet)\r\n",
    "    tweet_limpo = ' '.join(lista_tweet_sem_stopwords)\r\n",
    "    return tweet_limpo"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "#### CARREGANDO A BASE DE DADOS COM OS TWEETS CLASSIFICADOS COMO ***RELEVANTES*** E ***IRRELEVANTES*** MANUALMENTE:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "filename = 'la casa de papel.xlsx'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Separação do documento em dois DataFrames diferentes: **Treinamento** e **Teste**.\n",
    "\n",
    "- **Treinamento**: composto por 300 tweets classificados manualmente, será usado para *ensinar* o programa a classificar um tweets de acorodo com a sua relevância levando em conta as palavras em seu conteúdo.\n",
    "\n",
    "- **Teste**: composto por 200 tweets classificados manualmente, será usado para *testar* o programa classificador e comparar o resultado com a classificação feita à mão anteriormente. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train = pd.read_excel(filename)\r\n",
    "train['Treinamento'] = train['Treinamento'].apply(limpeza_total) #aplicando a função de limpeza\r\n",
    "train.head(5)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação (relevante = 1, não relevante = 0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tô vendo la casa papel mdssss primeiro ep tira...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agora vou assistir lá casa papel dormir porq a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dedo coçando pra assistir lá casa papel espera...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la casa papel faz torcer pros bandidos</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la casa papel acabou comigo encontro desidrata...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  \\\n",
       "0  tô vendo la casa papel mdssss primeiro ep tira...   \n",
       "1  agora vou assistir lá casa papel dormir porq a...   \n",
       "2  dedo coçando pra assistir lá casa papel espera...   \n",
       "3             la casa papel faz torcer pros bandidos   \n",
       "4  la casa papel acabou comigo encontro desidrata...   \n",
       "\n",
       "   Classificação (relevante = 1, não relevante = 0)  \n",
       "0                                               1.0  \n",
       "1                                               0.0  \n",
       "2                                               0.0  \n",
       "3                                               1.0  \n",
       "4                                               1.0  "
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**OBS**: a função de limpeza já foi aplicada no DataFrame de treinamento."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "test['Teste'] = test['Teste'].apply(limpeza_total)\r\n",
    "test.head(5)\r\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação (relevante = 1, não relevante = 0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quero terminar ver nova parte la casa papel má...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>existe outra série mundo mexa comigo la casa p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tá foda desviar todos spoilers la casa papel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>todoroki_jun né tô sentindo lá casa papel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la casa papel tão ruim consegui terminar so t ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  \\\n",
       "0  quero terminar ver nova parte la casa papel má...   \n",
       "1  existe outra série mundo mexa comigo la casa p...   \n",
       "2       tá foda desviar todos spoilers la casa papel   \n",
       "3          todoroki_jun né tô sentindo lá casa papel   \n",
       "4  la casa papel tão ruim consegui terminar so t ...   \n",
       "\n",
       "   Classificação (relevante = 1, não relevante = 0)  \n",
       "0                                                 0  \n",
       "1                                                 1  \n",
       "2                                                 1  \n",
       "3                                                 0  \n",
       "4                                                 1  "
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "#### CLASSIFICADOR AUTOMÁTICO DE SENTIMENTO:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "O filtro criado para a realização da classificação manual seguia o padrão especificado abaixo:\n",
    "\n",
    "**RELEVANTES**: As mensagens de texto com relevância mostravam a opinião e sentimentos, sejam eles positivos ou negativos, sobre a série.\n",
    "*Consideramos tweets relacionados a spoilers como relevantes pois eles também demonstram um forte sentimento que as pessoas possuem em relação à série.\n",
    "\n",
    "**IRRELEVANTES**: Classificamos como não relevantes tweets que não se encaixaram na nossa classificação de relevância, tweets que falavam sobre tópicos pessoais ou tweets que falavam sobre algum personagem específico da série.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "#### MONTANDO UM CLASSIFICADOR NAÏVE-BAYES:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- PREPARANDO OS DADOS DO TREINAMENTO"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#criando filtros para separar os tweets relevantes dos irrelevantes\r\n",
    "\r\n",
    "filtro_nao_relevante = train['Classificação (relevante = 1, não relevante = 0)']==0\r\n",
    "filtro_relevante = train['Classificação (relevante = 1, não relevante = 0)']==1\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "#separando em dois DFs diferentes os tweets relevantes e irrelevantes\r\n",
    "\r\n",
    "relevantes_train = train[filtro_relevante]\r\n",
    "nao_relevantes_train = train[filtro_nao_relevante]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "#criando uma string grande para armazenar todos os tweets de cada classificação\r\n",
    "\r\n",
    "relevantes_train_txt = ''\r\n",
    "for tweet in relevantes_train['Treinamento']:\r\n",
    "    relevantes_train_txt += \" \"\r\n",
    "    relevantes_train_txt += str(tweet)\r\n",
    "\r\n",
    "nao_relevantes_train_txt = ''\r\n",
    "for tweet in nao_relevantes_train['Treinamento']:\r\n",
    "    nao_relevantes_train_txt += \" \"\r\n",
    "    nao_relevantes_train_txt += str(tweet)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "#organizando os tweets em listas de palavras e pandas Series \r\n",
    "\r\n",
    "#fazendo a lista com todas as palavaras dos tweets\r\n",
    "todas_palavras_relevantes = relevantes_train_txt.split()\r\n",
    "todas_palavras_irrelevantes = nao_relevantes_train_txt.split()\r\n",
    "\r\n",
    "#transformando a lista em uma panda Series\r\n",
    "serie_relevante = pd.Series(todas_palavras_relevantes)\r\n",
    "serie_irrelevante = pd.Series(todas_palavras_irrelevantes)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- PREPARANDO AS TABELAS DE FREQUÊNCIA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "tabela_relevante = serie_relevante.value_counts()\r\n",
    "tabela_irrelevante = serie_irrelevante.value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Considerando que o conjunto universo seja apenas a soma de todas as palavras em tweets relevantes e irrelevantes, a seguir cria-se esse conjunto somando as strings de ambas. \n",
    "\n",
    "Além disso prossegu-se com o tratamento de dados criando uma lista com todas essas palavras e depois um pandas Series onde pode-se realizar a contagem da frequência de cada palavra e a partir daí começar o trinamento do programa partindo do conjunto universo de palavras.\n",
    "\n",
    "Para finalizar o tratamento do conjunto universo de palavras, cria-se uma lista de palavras excluindo as repetidas que serão usadas depois no método de ***Suavização de Laplace***."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#organizando o conjunto universo de todas as palavras\r\n",
    "\r\n",
    "palavras = relevantes_train_txt + nao_relevantes_train_txt\r\n",
    "todas_palavras = palavras.split()\r\n",
    "serie_palavras = pd.Series(todas_palavras)\r\n",
    "tabela_palavras = serie_palavras.value_counts(normalize=True)\r\n",
    "\r\n",
    "\r\n",
    "palavras_sem_repeticao = []\r\n",
    "for e in todas_palavras:\r\n",
    "    if e not in palavras_sem_repeticao:\r\n",
    "        palavras_sem_repeticao.append(e)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- MONTANDO AS PROBABILIDADES"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Definindo os eventos:\n",
    "\n",
    "- $P(tweet|R)$: probabilidade de o tweet ser classificado como relevante;\n",
    "- $P(tweet|IR)$: probabilidade de o tweet ser classificado como irrelevante;\n",
    "- $P(R)$: probabilidade de um tweet ser relevante;\n",
    "- $P(IR)$: probabilidade de um tweet ser irrelevante;\n",
    "\n",
    "$$\\quad P(R) = \\frac{N palavras RELEVANTES}{N total palavras}$$  \n",
    "$$\\quad P(IR) = \\frac{N palavras IRRELEVANTES}{N total palavras}$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#calculando a probabilidade de um tweet ser relevante ou irrelevante\r\n",
    "probR = len(serie_relevante)/len(serie_palavras)\r\n",
    "probIR = len(serie_irrelevante)/len(serie_palavras)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Aplicação do Teorema de Bayes:\n",
    "\n",
    "Apresentação do teorema:\n",
    "$\\quad P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$  \n",
    "  \n",
    "Que nesse contexto seria equivalente à:  \n",
    "  \n",
    "$$\\quad P(R|tweet) = \\frac{P(tweet|R)P(R)}{P(tweet)}$$  \n",
    "$$\\quad P(IR|tweet) = \\frac{P(tweet|IR)P(IR)}{P(tweet)}$$  \n",
    "  \n",
    "É necessário realizar o cálculo de $P(tweet|R)$ e $P(tweet|IR)$ para aplicar o teorema e desse modo calcular a probbilidade de o tweet ser classificado como **relevante** ou **irrelevante**."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#PRIMEIRA FUNÇÃO: calculando a probabilidade de uma X aparecer dado um dos conjuntos (relevante ou irrelevante)\r\n",
    "\r\n",
    "def probDadoconj(palavra, prob_conj, lista_palavras_conj):\r\n",
    "    if palavra in lista_palavras_conj:\r\n",
    "        return prob_conj[palavra]\r\n",
    "    else:\r\n",
    "        return 0\r\n",
    "\r\n",
    "#exemplo: print(probDadoconj(\"la\", tabela_relevante, todas_palavras_relevantes))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Suavização de Laplace (\"Laplace Soothing\"):\n",
    "\n",
    "Essa técnica é utilizada para evitar que uma probabilidade seja ZERO caso o Teorma de Bayes seja aplicado à uma amostra fora da base de dados que compõe o conjunto universo do que está sendo considerado a totalidade de palavras em tweets.  \n",
    "\n",
    "A possibilidade de resultar em zero vem do cálculo da probabilidade de um tweet ser classificado como relevante ou irrelevante já que é efetuada a multiplicação entre as probabilidades de cada palavra ser um indicador de relevância ou irrelevância.  \n",
    "\n",
    "Aplicando a suavização:\n",
    "$$\\quad P(palavra|conjunto) = \\frac{P(palavra|conjunto)+1}{palavras  conjunto + palavras sem repetição}$$  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "#SEGUNDA FUNÇÃO: aplicando a suavização de Laplace\r\n",
    "\r\n",
    "def aplicando_laplace(prob_dado_conj, lista_palavras_conj):\r\n",
    "    return (prob_dado_conj+1)/(len(lista_palavras_conj)+len(palavras_sem_repeticao))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Classificação final: \r\n",
    "\r\n",
    "Para realizar a classificação compila-se ambas as funções em uma só para que seja mais fácil de aplicar para todo o documento de tweets na base de treino.  \r\n",
    "\r\n",
    "Nela é calculada a probabilidade de um tweet ser classificado como relevante e como irrelevante e no fim é feita uma comparação retornando a classificação com maior probebilidade de ocorrer:  \r\n",
    "\r\n",
    "$\\quad \\Rightarrow$ Se $P(R|tweet) > P(IR|tweet)$, então o tweet será classificado como de **relevante**.\r\n",
    "\r\n",
    "$\\quad \\Rightarrow$ Se $P(IR|tweet) > P(R|tweet)$, então o tweet será classificado como de **irrelevante**.\r\n",
    "\r\n",
    "**Lembrando que**: a probabilidade é contruindo multiplicando a probabilidade de cada palavra na frase do tweet estar presente em relevância ou irrelevância:  \r\n",
    "\r\n",
    "$\\quad P(tweet|conj) = \r\n",
    "P(palavra1|conj)\\cdot P(palavra2|conj)\\cdot P(palavra3|conj)\\cdot P(palavra4|conj)\\cdot...$  \r\n",
    "\r\n",
    "E portanto a fórmula ficará:  \r\n",
    "\r\n",
    "$P(conj|tweet) = P(palavra1|conj)\\cdot P(palavra2|conj)\\cdot P(palavra3|conj)\\cdot P(palavra4|conj)\\cdot... P(conj)$  \r\n",
    "Vale ressaltar que a divisão por $P(tweet)$ não é necessária na hora de fazer a comparação uma vez que em ambas a probabilidades isso seria feito, então podemos tratá-lo como um fator comum no cálculo e desconsiderar a divisão por simplificação da fórmula."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "#FUNÇÃO FINAL: compilado das duas funções anteriores\r\n",
    "#essa funçã0 realiza duas vezes as funções escritas anteriormente e depois comparam seus resultados para classificar\r\n",
    "\r\n",
    "def Classificacao(tweet):\r\n",
    "    prob_relevante = 1\r\n",
    "    lista_tweet = tweet.split()\r\n",
    "    for palavra in lista_tweet:\r\n",
    "        prob = probDadoconj(palavra, tabela_relevante, todas_palavras_relevantes)\r\n",
    "        prob_laplace = aplicando_laplace(prob, todas_palavras_relevantes)\r\n",
    "        prob_relevante *= prob_laplace\r\n",
    "    probRtweet = prob_relevante*probR\r\n",
    "    prob_irrelevante = 1\r\n",
    "    for palavra in lista_tweet:\r\n",
    "        prob = probDadoconj(palavra, tabela_irrelevante, todas_palavras_irrelevantes)\r\n",
    "        prob_laplace = aplicando_laplace(prob, todas_palavras_irrelevantes)\r\n",
    "        prob_irrelevante *= prob_laplace\r\n",
    "    probIRtweet = prob_irrelevante*probIR\r\n",
    "    if probRtweet < probIRtweet: \r\n",
    "        return 0\r\n",
    "    else: \r\n",
    "        return 1\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Testando a função na base de treinamento: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "train['Classificacao_Naive_Bayes'] = train.Treinamento.apply(Classificacao)\r\n",
    "train"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação (relevante = 1, não relevante = 0)</th>\n",
       "      <th>Classificacao_Naive_Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tô vendo la casa papel mdssss primeiro ep tira...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agora vou assistir lá casa papel dormir porq a...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dedo coçando pra assistir lá casa papel espera...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la casa papel faz torcer pros bandidos</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la casa papel acabou comigo encontro desidrata...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tô aqui assistindo la casa papel ler todos spo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>achei nenhuma morte la casa papel ia superar n...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>caralho to chorando igual vagabunda porra la c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>cara nunca chorei tanto quanto chorei olhando ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>caralhos la casa papel</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  \\\n",
       "0    tô vendo la casa papel mdssss primeiro ep tira...   \n",
       "1    agora vou assistir lá casa papel dormir porq a...   \n",
       "2    dedo coçando pra assistir lá casa papel espera...   \n",
       "3               la casa papel faz torcer pros bandidos   \n",
       "4    la casa papel acabou comigo encontro desidrata...   \n",
       "..                                                 ...   \n",
       "295  tô aqui assistindo la casa papel ler todos spo...   \n",
       "296  achei nenhuma morte la casa papel ia superar n...   \n",
       "297  caralho to chorando igual vagabunda porra la c...   \n",
       "298  cara nunca chorei tanto quanto chorei olhando ...   \n",
       "299                             caralhos la casa papel   \n",
       "\n",
       "     Classificação (relevante = 1, não relevante = 0)  \\\n",
       "0                                                 1.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 1.0   \n",
       "4                                                 1.0   \n",
       "..                                                ...   \n",
       "295                                               0.0   \n",
       "296                                               1.0   \n",
       "297                                               1.0   \n",
       "298                                               1.0   \n",
       "299                                               1.0   \n",
       "\n",
       "     Classificacao_Naive_Bayes  \n",
       "0                            1  \n",
       "1                            0  \n",
       "2                            0  \n",
       "3                            1  \n",
       "4                            1  \n",
       "..                         ...  \n",
       "295                          0  \n",
       "296                          1  \n",
       "297                          1  \n",
       "298                          1  \n",
       "299                          1  \n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "#Porcentagem de acerto no conjunto de Treino:\r\n",
    "\r\n",
    "verdadeiros_positivos_train=train.loc[(train['Classificacao_Naive_Bayes']==1)&(train['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "verdadeiros_negativos_train=train.loc[(train['Classificacao_Naive_Bayes']==0)&(train['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "print(f'A acurácia na base de treinamento foi de: {((verdadeiros_positivos_train+verdadeiros_negativos_train)/train.shape[0])*100}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A acurácia na base de treinamento foi de: 94.33333333333334%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "#### BASE DE TESTE:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Verificando a performance do Classificador \r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "test['Classificacao_Naive_Bayes'] = test['Teste'].apply(Classificacao)\r\n",
    "test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação (relevante = 1, não relevante = 0)</th>\n",
       "      <th>Classificacao_Naive_Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quero terminar ver nova parte la casa papel má...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>existe outra série mundo mexa comigo la casa p...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tá foda desviar todos spoilers la casa papel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>todoroki_jun né tô sentindo lá casa papel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la casa papel tão ruim consegui terminar so t ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>respeito casal fav la casa papel morto literal...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>assistindo la casa papel poder falar mal mão_e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>sexo kk veste roupa aí gente vai maratonar la ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>deus final la casa papel…………</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>sexo rosto_com_sobrancelha_levantada naokkkkk ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  \\\n",
       "0    quero terminar ver nova parte la casa papel má...   \n",
       "1    existe outra série mundo mexa comigo la casa p...   \n",
       "2         tá foda desviar todos spoilers la casa papel   \n",
       "3            todoroki_jun né tô sentindo lá casa papel   \n",
       "4    la casa papel tão ruim consegui terminar so t ...   \n",
       "..                                                 ...   \n",
       "195  respeito casal fav la casa papel morto literal...   \n",
       "196  assistindo la casa papel poder falar mal mão_e...   \n",
       "197  sexo kk veste roupa aí gente vai maratonar la ...   \n",
       "198                       deus final la casa papel…………   \n",
       "199  sexo rosto_com_sobrancelha_levantada naokkkkk ...   \n",
       "\n",
       "     Classificação (relevante = 1, não relevante = 0)  \\\n",
       "0                                                   0   \n",
       "1                                                   1   \n",
       "2                                                   1   \n",
       "3                                                   0   \n",
       "4                                                   1   \n",
       "..                                                ...   \n",
       "195                                                 0   \n",
       "196                                                 0   \n",
       "197                                                 0   \n",
       "198                                                 1   \n",
       "199                                                 0   \n",
       "\n",
       "     Classificacao_Naive_Bayes  \n",
       "0                            0  \n",
       "1                            1  \n",
       "2                            1  \n",
       "3                            1  \n",
       "4                            0  \n",
       "..                         ...  \n",
       "195                          1  \n",
       "196                          0  \n",
       "197                          0  \n",
       "198                          1  \n",
       "199                          0  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porcentagem de verdadeiros positivos (mensagens relevantes e que são classificadas como relevantes):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "verdadeiros_positivos=test.loc[(test['Classificacao_Naive_Bayes']==1)&(test['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "print(f'A porcentagem de verdadeiros positivos na base de teste foi de: {(verdadeiros_positivos/test.shape[0])*100}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A porcentagem de verdadeiros positivos na base de teste foi de: 51.0%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porcentagem de falsos positivos (mensagens irrelevantes e que são classificadas como relevantes):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "falsos_positivos=test.loc[(test['Classificacao_Naive_Bayes']==1)&(test['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "print(f'A porcentagem de falsos positivos na base de teste foi de: {(falsos_positivos/test.shape[0])*100}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A porcentagem de falsos positivos na base de teste foi de: 22.5%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porcentagem de verdadeiros negativos (mensagens irrelevantes e que são classificadas como irrelevantes):\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "verdadeiros_negativos=test.loc[(test['Classificacao_Naive_Bayes']==0)&(test['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "print(f'A porcentagem de verdadeiros negativos na base de teste foi de: {(verdadeiros_negativos/test.shape[0])*100}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A porcentagem de verdadeiros negativos na base de teste foi de: 19.5%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Porcentagem de falsos negativos (mensagens relevantes e que são classificadas como irrelevantes):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "falsos_negativos=test.loc[(test['Classificacao_Naive_Bayes']==0)&(test['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "print(f'A porcentagem de falsos negativos na base de teste foi de: {(falsos_negativos/test.shape[0])*100}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A porcentagem de falsos negativos na base de teste foi de: 7.000000000000001%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Acurácia (mensagens corretamente classificadas, independente da categoria):"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "print(f'A acurácia na base de teste foi de: {((verdadeiros_positivos+verdadeiros_negativos)/test.shape[0])*100}%')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "A acurácia na base de teste foi de: 70.5%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Concluindo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "train_para_concat = train\r\n",
    "train_para_concat = train_para_concat.rename(columns={\"Treinamento\": \"Tweets\"})\r\n",
    "train_para_concat =train_para_concat.drop(['Classificacao_Naive_Bayes'], axis=1)\r\n",
    "train_para_concat"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Classificação (relevante = 1, não relevante = 0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tô vendo la casa papel mdssss primeiro ep tira...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agora vou assistir lá casa papel dormir porq a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dedo coçando pra assistir lá casa papel espera...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la casa papel faz torcer pros bandidos</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la casa papel acabou comigo encontro desidrata...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>tô aqui assistindo la casa papel ler todos spo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>achei nenhuma morte la casa papel ia superar n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>caralho to chorando igual vagabunda porra la c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>cara nunca chorei tanto quanto chorei olhando ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>caralhos la casa papel</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweets  \\\n",
       "0    tô vendo la casa papel mdssss primeiro ep tira...   \n",
       "1    agora vou assistir lá casa papel dormir porq a...   \n",
       "2    dedo coçando pra assistir lá casa papel espera...   \n",
       "3               la casa papel faz torcer pros bandidos   \n",
       "4    la casa papel acabou comigo encontro desidrata...   \n",
       "..                                                 ...   \n",
       "295  tô aqui assistindo la casa papel ler todos spo...   \n",
       "296  achei nenhuma morte la casa papel ia superar n...   \n",
       "297  caralho to chorando igual vagabunda porra la c...   \n",
       "298  cara nunca chorei tanto quanto chorei olhando ...   \n",
       "299                             caralhos la casa papel   \n",
       "\n",
       "     Classificação (relevante = 1, não relevante = 0)  \n",
       "0                                                 1.0  \n",
       "1                                                 0.0  \n",
       "2                                                 0.0  \n",
       "3                                                 1.0  \n",
       "4                                                 1.0  \n",
       "..                                                ...  \n",
       "295                                               0.0  \n",
       "296                                               1.0  \n",
       "297                                               1.0  \n",
       "298                                               1.0  \n",
       "299                                               1.0  \n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "test_para_concat = test\r\n",
    "test_para_concat = test_para_concat.rename(columns={\"Teste\": \"Tweets\"})\r\n",
    "test_para_concat =test_para_concat.drop(['Classificacao_Naive_Bayes'], axis=1)\r\n",
    "test_para_concat"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Classificação (relevante = 1, não relevante = 0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>quero terminar ver nova parte la casa papel má...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>existe outra série mundo mexa comigo la casa p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tá foda desviar todos spoilers la casa papel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>todoroki_jun né tô sentindo lá casa papel</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la casa papel tão ruim consegui terminar so t ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>respeito casal fav la casa papel morto literal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>assistindo la casa papel poder falar mal mão_e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>sexo kk veste roupa aí gente vai maratonar la ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>deus final la casa papel…………</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>sexo rosto_com_sobrancelha_levantada naokkkkk ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweets  \\\n",
       "0    quero terminar ver nova parte la casa papel má...   \n",
       "1    existe outra série mundo mexa comigo la casa p...   \n",
       "2         tá foda desviar todos spoilers la casa papel   \n",
       "3            todoroki_jun né tô sentindo lá casa papel   \n",
       "4    la casa papel tão ruim consegui terminar so t ...   \n",
       "..                                                 ...   \n",
       "195  respeito casal fav la casa papel morto literal...   \n",
       "196  assistindo la casa papel poder falar mal mão_e...   \n",
       "197  sexo kk veste roupa aí gente vai maratonar la ...   \n",
       "198                       deus final la casa papel…………   \n",
       "199  sexo rosto_com_sobrancelha_levantada naokkkkk ...   \n",
       "\n",
       "     Classificação (relevante = 1, não relevante = 0)  \n",
       "0                                                   0  \n",
       "1                                                   1  \n",
       "2                                                   1  \n",
       "3                                                   0  \n",
       "4                                                   1  \n",
       "..                                                ...  \n",
       "195                                                 0  \n",
       "196                                                 0  \n",
       "197                                                 0  \n",
       "198                                                 1  \n",
       "199                                                 0  \n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "base_inteira_tweets = pd.concat([train_para_concat, test_para_concat], ignore_index=True, sort=False)\r\n",
    "base_inteira_tweets"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Classificação (relevante = 1, não relevante = 0)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tô vendo la casa papel mdssss primeiro ep tira...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agora vou assistir lá casa papel dormir porq a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dedo coçando pra assistir lá casa papel espera...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la casa papel faz torcer pros bandidos</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>la casa papel acabou comigo encontro desidrata...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>respeito casal fav la casa papel morto literal...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>assistindo la casa papel poder falar mal mão_e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>sexo kk veste roupa aí gente vai maratonar la ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>deus final la casa papel…………</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>sexo rosto_com_sobrancelha_levantada naokkkkk ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweets  \\\n",
       "0    tô vendo la casa papel mdssss primeiro ep tira...   \n",
       "1    agora vou assistir lá casa papel dormir porq a...   \n",
       "2    dedo coçando pra assistir lá casa papel espera...   \n",
       "3               la casa papel faz torcer pros bandidos   \n",
       "4    la casa papel acabou comigo encontro desidrata...   \n",
       "..                                                 ...   \n",
       "495  respeito casal fav la casa papel morto literal...   \n",
       "496  assistindo la casa papel poder falar mal mão_e...   \n",
       "497  sexo kk veste roupa aí gente vai maratonar la ...   \n",
       "498                       deus final la casa papel…………   \n",
       "499  sexo rosto_com_sobrancelha_levantada naokkkkk ...   \n",
       "\n",
       "     Classificação (relevante = 1, não relevante = 0)  \n",
       "0                                                 1.0  \n",
       "1                                                 0.0  \n",
       "2                                                 0.0  \n",
       "3                                                 1.0  \n",
       "4                                                 1.0  \n",
       "..                                                ...  \n",
       "495                                               0.0  \n",
       "496                                               0.0  \n",
       "497                                               0.0  \n",
       "498                                               1.0  \n",
       "499                                               0.0  \n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Separando a base inteira entre treinamento e teste 100 vezes e calculando a acurácia do classificador em cada uma das separações:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "lista_acuracias = []\r\n",
    "for i in range(100):\r\n",
    "    #separando a base completa aleatoriamente entre train e test, mantendo a proporção de 200 tweets como teste (40%) e os outros 300 (60%) como treinamento\r\n",
    "    base_train, base_test = train_test_split(base_inteira_tweets, test_size=0.4, random_state=None)\r\n",
    "    #criando filtros para separar os tweets relevantes dos irrelevantes\r\n",
    "    filtro_nao_relevante = base_train['Classificação (relevante = 1, não relevante = 0)']==0\r\n",
    "    filtro_relevante = base_train['Classificação (relevante = 1, não relevante = 0)']==1\r\n",
    "\r\n",
    "    #separando em dois DFs diferentes os tweets relevantes e irrelevantes\r\n",
    "    relevantes_train = base_train[filtro_relevante]\r\n",
    "    nao_relevantes_train = base_train[filtro_nao_relevante]\r\n",
    "\r\n",
    "    #criando uma string grande para armazenar todos os tweets de cada classificação\r\n",
    "    relevantes_train_txt = ''\r\n",
    "    for tweet in relevantes_train['Tweets']:\r\n",
    "        relevantes_train_txt += \" \"\r\n",
    "        relevantes_train_txt += str(tweet)\r\n",
    "    nao_relevantes_train_txt = ''\r\n",
    "    for tweet in nao_relevantes_train['Tweets']:\r\n",
    "        nao_relevantes_train_txt += \" \"\r\n",
    "        nao_relevantes_train_txt += str(tweet)\r\n",
    "    \r\n",
    "    #organizando os tweets em listas de palavras e pandas Series \r\n",
    "\r\n",
    "    #fazendo a lista com todas as palavaras dos tweets\r\n",
    "    todas_palavras_relevantes = relevantes_train_txt.split()\r\n",
    "    todas_palavras_irrelevantes = nao_relevantes_train_txt.split()\r\n",
    "\r\n",
    "    #transformando a lista em uma panda Series\r\n",
    "    serie_relevante = pd.Series(todas_palavras_relevantes)\r\n",
    "    serie_irrelevante = pd.Series(todas_palavras_irrelevantes)\r\n",
    "\r\n",
    "    tabela_relevante = serie_relevante.value_counts()\r\n",
    "    tabela_irrelevante = serie_irrelevante.value_counts()\r\n",
    "\r\n",
    "    #organizando o conjunto universo de todas as palavras\r\n",
    "\r\n",
    "    palavras = relevantes_train_txt + nao_relevantes_train_txt\r\n",
    "    todas_palavras = palavras.split()\r\n",
    "    serie_palavras = pd.Series(todas_palavras)\r\n",
    "    tabela_palavras = serie_palavras.value_counts(normalize=True)\r\n",
    "\r\n",
    "\r\n",
    "    palavras_sem_repeticao = []\r\n",
    "    for e in todas_palavras:\r\n",
    "        if e not in palavras_sem_repeticao:\r\n",
    "            palavras_sem_repeticao.append(e)\r\n",
    "    \r\n",
    "    #calculando a probabilidade de um tweet ser relevante ou irrelevante\r\n",
    "    probR = len(serie_relevante)/len(serie_palavras)\r\n",
    "    probIR = len(serie_irrelevante)/len(serie_palavras)\r\n",
    "\r\n",
    "    base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\r\n",
    "    verdadeiros_positivos=base_test.loc[(base_test['Classificacao_Naive_Bayes']==1)&(base_test['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "    verdadeiros_negativos=base_test.loc[(base_test['Classificacao_Naive_Bayes']==0)&(base_test['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "    acuracia = (verdadeiros_positivos+verdadeiros_negativos)/base_test.shape[0]\r\n",
    "    lista_acuracias.append(acuracia)\r\n",
    "\r\n",
    "\r\n",
    "lista_acuracias"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-55-10b3765def0a>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.775,\n",
       " 0.695,\n",
       " 0.72,\n",
       " 0.745,\n",
       " 0.71,\n",
       " 0.7,\n",
       " 0.685,\n",
       " 0.735,\n",
       " 0.73,\n",
       " 0.815,\n",
       " 0.675,\n",
       " 0.74,\n",
       " 0.705,\n",
       " 0.66,\n",
       " 0.705,\n",
       " 0.715,\n",
       " 0.735,\n",
       " 0.705,\n",
       " 0.705,\n",
       " 0.715,\n",
       " 0.76,\n",
       " 0.745,\n",
       " 0.7,\n",
       " 0.715,\n",
       " 0.76,\n",
       " 0.72,\n",
       " 0.675,\n",
       " 0.745,\n",
       " 0.715,\n",
       " 0.725,\n",
       " 0.67,\n",
       " 0.74,\n",
       " 0.695,\n",
       " 0.725,\n",
       " 0.73,\n",
       " 0.725,\n",
       " 0.735,\n",
       " 0.675,\n",
       " 0.7,\n",
       " 0.72,\n",
       " 0.725,\n",
       " 0.74,\n",
       " 0.725,\n",
       " 0.675,\n",
       " 0.7,\n",
       " 0.8,\n",
       " 0.74,\n",
       " 0.7,\n",
       " 0.69,\n",
       " 0.695,\n",
       " 0.715,\n",
       " 0.715,\n",
       " 0.71,\n",
       " 0.715,\n",
       " 0.7,\n",
       " 0.72,\n",
       " 0.735,\n",
       " 0.725,\n",
       " 0.73,\n",
       " 0.685,\n",
       " 0.69,\n",
       " 0.78,\n",
       " 0.745,\n",
       " 0.68,\n",
       " 0.76,\n",
       " 0.745,\n",
       " 0.78,\n",
       " 0.72,\n",
       " 0.695,\n",
       " 0.705,\n",
       " 0.71,\n",
       " 0.72,\n",
       " 0.725,\n",
       " 0.71,\n",
       " 0.685,\n",
       " 0.73,\n",
       " 0.73,\n",
       " 0.69,\n",
       " 0.74,\n",
       " 0.68,\n",
       " 0.675,\n",
       " 0.66,\n",
       " 0.705,\n",
       " 0.79,\n",
       " 0.75,\n",
       " 0.76,\n",
       " 0.705,\n",
       " 0.73,\n",
       " 0.705,\n",
       " 0.755,\n",
       " 0.67,\n",
       " 0.675,\n",
       " 0.735,\n",
       " 0.69,\n",
       " 0.75,\n",
       " 0.715,\n",
       " 0.69,\n",
       " 0.73,\n",
       " 0.69,\n",
       " 0.675]"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "plt.figure(figsize=(20, 20))\r\n",
    "plt.hist(lista_acuracias, edgecolor='white', color='moccasin', density=True)\r\n",
    "plt.title('Histograma de acurácia do classificador em 100 simulações')\r\n",
    "plt.ylabel('densidade')\r\n",
    "plt.xlabel('acurácia [entre 0 e 1]')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'acurácia [entre 0 e 1]')"
      ]
     },
     "metadata": {},
     "execution_count": 59
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## Referências"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96eb50e1d44aed467dc8f759cb08c32fbfa9babcf79c554e2d0e5feb04653a10"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}