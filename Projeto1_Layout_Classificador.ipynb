{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Arthur Cisotto Machado\n",
    "\n",
    "Nome: Alessandra Yumi Carvalho Ogawa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONTEXTO DO PROJETO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A empresa de streaming *Netflix* em parceria com o estúdio espanhol *Vancouver Media* deseja saber e analisar como a audiencia está reagindo a série de sucesso *La Casa de Papel* na rede social Twitter. \n",
    "O projeto exige a criação de um programa que consiga classificar os tweets entre **relevantes** ou **irrelevantes** para a análise da empresa.\n",
    "\n",
    "A classificação foi feita com o intúito de ajudar a área de marketing das duas empresas parceiras a acharem comentários que possam ser úteis em algum sentido estratégio para mudança de operações internas e também como fonte de *feedback* em relação ao conteúdo cinematográfico produzido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\r\n",
    "#### CARREGANDO AS BIBLIOTECAS UTILIZADAS NO PROGRAMA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alessandrayumiogawa/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alessandrayumiogawa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "import emoji\n",
    "from emoji import UNICODE_EMOJI\n",
    "import nltk \n",
    "from nltk.stem import RSLPStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "/Users/alessandrayumiogawa/Documents/INSPER/INSPER - 2A/C-DADOS/P1_CDados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\r\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\r\n",
    "#### FUNÇÃO DE LIMPEZA DOS TWEETS:\r\n",
    "- tira sinais de pontuação irrelevantes para o texto;\r\n",
    "- todas as fontes são convertidas para letras minúsculas para evitar diferenciação pelo classificador;\r\n",
    "- exclui repetição de emoji;\r\n",
    "- substitui emoji por seu código;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\r\n",
    "\r\n",
    "\r\n",
    "def cleanup(text):\r\n",
    "\r\n",
    "    punctuation = '[”/-@\\\\n:;?\\\"\\'().,]' \r\n",
    "    pattern = re.compile(punctuation)\r\n",
    "    text_subbed = re.sub(pattern, ' ', text)\r\n",
    "    text_split = text_subbed.split()\r\n",
    "    return ' '.join(text_split).lower()\r\n",
    "\r\n",
    "def limpa_emoji(tweet):\r\n",
    "    \r\n",
    "    modified=' '.join(emoji.get_emoji_regexp().split(tweet))\r\n",
    "    modified=modified.split()\r\n",
    "    for i,emoji1 in enumerate(modified):\r\n",
    "        if emoji1 in UNICODE_EMOJI['pt']:\r\n",
    "            modified[i]=UNICODE_EMOJI['pt'][emoji1].replace(':','')\r\n",
    "        elif emoji1 in UNICODE_EMOJI['en']:\r\n",
    "            modified[i]=UNICODE_EMOJI['en'][emoji1].replace(':','')\r\n",
    "        else:\r\n",
    "            continue\r\n",
    "    modified=' '.join(modified)\r\n",
    "        \r\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OUTRAS FUNÇÕES DE LIMPEZA \r\n",
    "Como proposta de outras limpezas/transformações que não afetem a qualidade da informação decidimos fazer a limpeza de stopwords, isso é, a remoção de palavras como preposições, pronomes, artigos e verbos de estado que não afetam a qualidade do conteúdo geral dos tweets.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Função que remove palavras comuns que não afetam a qualidade da informação contida, como preposições, pronomes, artigos e verbos de estado.\r\n",
    "def remove_stopwords(lista_palavras):\r\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\r\n",
    "    frase = []\r\n",
    "    for palavra in lista_palavras:\r\n",
    "        if palavra not in stopwords:\r\n",
    "            frase.append(palavra)\r\n",
    "    return frase\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "##Todas as palavras consideradas como stopwords pela biblioteca usada:\r\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\r\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilado das funções de limpeza em uma só para mais fácil aplicação\r\n",
    "def limpeza_total(tweet):\r\n",
    "    texto_sem_pontuacoes = cleanup(tweet)\r\n",
    "    sem_emoji = limpa_emoji(texto_sem_pontuacoes)\r\n",
    "    lista_tweet = sem_emoji.split()\r\n",
    "    lista_tweet_sem_stopwords = remove_stopwords(lista_tweet)\r\n",
    "    tweet_limpo = ' '.join(lista_tweet_sem_stopwords)\r\n",
    "    return tweet_limpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### CARREGANDO A BASE DE DADOS COM OS TWEETS CLASSIFICADOS COMO ***RELEVANTES*** E ***IRRELEVANTES*** MANUALMENTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'la casa de papel.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação do documento em dois DataFrames diferentes: **Treinamento** e **Teste**.\n",
    "\n",
    "- **Treinamento**: composto por 300 tweets classificados manualmente, será usado para *ensinar* o programa a classificar um tweets de acorodo com a sua relevância levando em conta as palavras em seu conteúdo.\n",
    "\n",
    "- **Teste**: composto por 200 tweets classificados manualmente, será usado para *testar* o programa classificador e comparar o resultado com a classificação feita à mão anteriormente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Treinamento</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tô vendo la casa papel mdssss primeiro ep tira...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>agora vou assistir lá casa papel dormir porq a...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dedo coçando pra assistir lá casa papel espera...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>la casa papel faz torcer pros bandidos</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la casa papel acabou comigo encontro desidrata...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                         Treinamento  \\\n0  tô vendo la casa papel mdssss primeiro ep tira...   \n1  agora vou assistir lá casa papel dormir porq a...   \n2  dedo coçando pra assistir lá casa papel espera...   \n3             la casa papel faz torcer pros bandidos   \n4  la casa papel acabou comigo encontro desidrata...   \n\n   Classificação (relevante = 1, não relevante = 0)  \n0                                               1.0  \n1                                               0.0  \n2                                               0.0  \n3                                               1.0  \n4                                               1.0  "
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\r\n",
    "train['Treinamento'] = train['Treinamento'].apply(limpeza_total) #aplicando a função de limpeza\r\n",
    "train.head(5)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Teste</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>quero terminar ver nova parte la casa papel má...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>existe outra série mundo mexa comigo la casa p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tá foda desviar todos spoilers la casa papel</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>todoroki_jun né tô sentindo lá casa papel</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la casa papel tão ruim consegui terminar so t ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                               Teste  \\\n0  quero terminar ver nova parte la casa papel má...   \n1  existe outra série mundo mexa comigo la casa p...   \n2       tá foda desviar todos spoilers la casa papel   \n3          todoroki_jun né tô sentindo lá casa papel   \n4  la casa papel tão ruim consegui terminar so t ...   \n\n   Classificação (relevante = 1, não relevante = 0)  \n0                                                 0  \n1                                                 1  \n2                                                 1  \n3                                                 0  \n4                                                 1  "
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "test['Teste'] = test['Teste'].apply(limpeza_total)\r\n",
    "test.head(5)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS**: a função de limpeza já foi aplicada no DataFrame de treinamento e  teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### CLASSIFICADOR AUTOMÁTICO DE SENTIMENTO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O filtro criado para a realização da classificação manual seguia o padrão especificado abaixo:\n",
    "\n",
    "**RELEVANTES**: As mensagens de texto com relevância mostravam a opinião e sentimentos, sejam eles positivos ou negativos, sobre a série.\n",
    "*Consideramos tweets relacionados a spoilers como relevantes pois eles também demonstram um forte sentimento que as pessoas possuem em relação à série.\n",
    "\n",
    "**IRRELEVANTES**: Classificamos como não relevantes tweets que não se encaixaram na nossa classificação de relevância, tweets que falavam sobre tópicos pessoais ou tweets que falavam sobre algum personagem específico da série.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### MONTANDO UM CLASSIFICADOR NAÏVE-BAYES:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PREPARANDO OS DADOS DO TREINAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando filtros para separar os tweets relevantes dos irrelevantes\r\n",
    "\r\n",
    "filtro_nao_relevante = train['Classificação (relevante = 1, não relevante = 0)']==0\r\n",
    "filtro_relevante = train['Classificação (relevante = 1, não relevante = 0)']==1\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando em dois DFs diferentes os tweets relevantes e irrelevantes\r\n",
    "\r\n",
    "relevantes_train = train[filtro_relevante]\r\n",
    "nao_relevantes_train = train[filtro_nao_relevante]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando uma string grande para armazenar todos os tweets de cada classificação\r\n",
    "\r\n",
    "relevantes_train_txt = ''\r\n",
    "for tweet in relevantes_train['Treinamento']:\r\n",
    "    relevantes_train_txt += \" \"\r\n",
    "    relevantes_train_txt += str(tweet)\r\n",
    "\r\n",
    "nao_relevantes_train_txt = ''\r\n",
    "for tweet in nao_relevantes_train['Treinamento']:\r\n",
    "    nao_relevantes_train_txt += \" \"\r\n",
    "    nao_relevantes_train_txt += str(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organizando os tweets em listas de palavras e pandas Series \r\n",
    "\r\n",
    "#fazendo a lista com todas as palavaras dos tweets\r\n",
    "todas_palavras_relevantes = relevantes_train_txt.split()\r\n",
    "todas_palavras_irrelevantes = nao_relevantes_train_txt.split()\r\n",
    "\r\n",
    "#transformando a lista em uma panda Series\r\n",
    "serie_relevante = pd.Series(todas_palavras_relevantes)\r\n",
    "serie_irrelevante = pd.Series(todas_palavras_irrelevantes)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PREPARANDO AS TABELAS DE FREQUÊNCIA ABSOLUTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relevante = serie_relevante.value_counts()\r\n",
    "tabela_irrelevante = serie_irrelevante.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando que o conjunto universo seja apenas a soma de todas as palavras em tweets relevantes e irrelevantes na base de treinamento, a seguir cria-se esse conjunto somando as strings de ambas. \r\n",
    "\r\n",
    "Além disso prosseguiu-se com o tratamento de dados criando uma lista com todas essas palavras e depois um pandas Series onde pode-se realizar a contagem da frequência de cada palavra e a partir daí começar o treinamento do programa partindo do conjunto universo de palavras.\r\n",
    "\r\n",
    "Para finalizar o tratamento do conjunto universo de palavras, cria-se uma lista de palavras excluindo as repetidas que serão usadas depois no método de ***Suavização de Laplace***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organizando o conjunto universo de todas as palavras\r\n",
    "\r\n",
    "palavras = relevantes_train_txt + nao_relevantes_train_txt\r\n",
    "todas_palavras = palavras.split()\r\n",
    "serie_palavras = pd.Series(todas_palavras)\r\n",
    "tabela_palavras = serie_palavras.value_counts(normalize=True)\r\n",
    "\r\n",
    "\r\n",
    "palavras_sem_repeticao = []\r\n",
    "for e in todas_palavras:\r\n",
    "    if e not in palavras_sem_repeticao:\r\n",
    "        palavras_sem_repeticao.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MONTANDO AS PROBABILIDADES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definindo os eventos:\n",
    "\n",
    "- $P(tweet|R)$: probabilidade de o tweet ser classificado como relevante;\n",
    "- $P(tweet|IR)$: probabilidade de o tweet ser classificado como irrelevante;\n",
    "- $P(R)$: probabilidade de um tweet ser relevante;\n",
    "- $P(IR)$: probabilidade de um tweet ser irrelevante;\n",
    "\n",
    "$$\\quad P(R) = \\frac{N palavras RELEVANTES}{N total palavras}$$  \n",
    "$$\\quad P(IR) = \\frac{N palavras IRRELEVANTES}{N total palavras}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculando a probabilidade de um tweet ser relevante ou irrelevante\r\n",
    "probR = len(serie_relevante)/len(serie_palavras)\r\n",
    "probIR = len(serie_irrelevante)/len(serie_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aplicação do Teorema de Bayes:\n",
    "\n",
    "Apresentação do teorema:\n",
    "$\\quad P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$  \n",
    "  \n",
    "Que nesse contexto seria equivalente à:  \n",
    "  \n",
    "$$\\quad P(R|tweet) = \\frac{P(tweet|R)P(R)}{P(tweet)}$$  \n",
    "$$\\quad P(IR|tweet) = \\frac{P(tweet|IR)P(IR)}{P(tweet)}$$  \n",
    "  \n",
    "É necessário realizar o cálculo de $P(tweet|R)$ e $P(tweet|IR)$ para aplicar o teorema e desse modo calcular a probbilidade de o tweet ser classificado como **relevante** ou **irrelevante**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRIMEIRA FUNÇÃO: calculando a probabilidade de uma X aparecer dado um dos conjuntos (relevante ou irrelevante)\r\n",
    "\r\n",
    "def probDadoconj(palavra, prob_conj, lista_palavras_conj):\r\n",
    "    if palavra in lista_palavras_conj:\r\n",
    "        return prob_conj[palavra]\r\n",
    "    else:\r\n",
    "        return 0\r\n",
    "\r\n",
    "#exemplo: print(probDadoconj(\"la\", tabela_relevante, todas_palavras_relevantes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Suavização de Laplace (\"Laplace Soothing\"):\r\n",
    "\r\n",
    "Essa técnica é utilizada para evitar que uma probabilidade seja ZERO caso o Teorema de Bayes seja aplicado à uma amostra fora da base de dados que compõe o conjunto universo do que está sendo considerado como a totalidade de palavras em tweets.  \r\n",
    "\r\n",
    "A possibilidade de resultar em zero vem do cálculo da probabilidade de um tweet ser classificado como relevante ou irrelevante já que é efetuada a multiplicação entre as probabilidades de cada palavra ser um indicador de relevância ou irrelevância.  \r\n",
    "\r\n",
    "Aplicando a suavização:\r\n",
    "$$\\quad P(palavra|conjunto) = \\frac{P(palavra|conjunto)+1}{palavras  conjunto + palavras sem repetição}$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEGUNDA FUNÇÃO: aplicando a suavização de Laplace\r\n",
    "\r\n",
    "def aplicando_laplace(prob_dado_conj, lista_palavras_conj):\r\n",
    "    return (prob_dado_conj+1)/(len(lista_palavras_conj)+len(palavras_sem_repeticao))\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CLASSIFICAÇÃO FINAL: \n",
    "\n",
    "Para realizar a classificação compila-se ambas as funções em uma só para que seja mais fácil de aplicar para todo o documento de tweets na base de treino.  \n",
    "\n",
    "Nela é calculada a probabilidade de um tweet ser classificado como relevante e como irrelevante e no fim é feita uma comparação retornando a classificação com maior probabilidade de ocorrer:  \n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(R|tweet) > P(IR|tweet)$, então o tweet será classificado como de **relevante**.\n",
    "\n",
    "$\\quad \\Rightarrow$ Se $P(IR|tweet) > P(R|tweet)$, então o tweet será classificado como de **irrelevante**.\n",
    "\n",
    "**Lembrando que**: a probabilidade é construída multiplicando a probabilidade de cada palavra na frase do tweet estar presente em relevância ou irrelevância:  \n",
    "\n",
    "$\\quad P(tweet|conj) = \n",
    "P(palavra1|conj)\\cdot P(palavra2|conj)\\cdot P(palavra3|conj)\\cdot P(palavra4|conj)\\cdot...$  \n",
    "\n",
    "E portanto a fórmula ficará:  \n",
    "\n",
    "$P(conj|tweet) = P(palavra1|conj)\\cdot P(palavra2|conj)\\cdot P(palavra3|conj)\\cdot P(palavra4|conj)\\cdot... P(conj)$  \n",
    "Vale ressaltar que a divisão por $P(tweet)$ não é necessária na hora de fazer a comparação uma vez que em ambas a probabilidades isso seria feito, então podemos tratá-lo como um fator comum no cálculo e desconsiderar a divisão por simplificação da fórmula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNÇÃO FINAL: compilado das duas funções anteriores\r\n",
    "#essa função realiza duas vezes as funções escritas anteriormente e depois comparam seus resultados para classificar\r\n",
    "\r\n",
    "def Classificacao(tweet):\r\n",
    "    prob_relevante = 1\r\n",
    "    lista_tweet = tweet.split()\r\n",
    "    for palavra in lista_tweet:\r\n",
    "        prob = probDadoconj(palavra, tabela_relevante, todas_palavras_relevantes)\r\n",
    "        prob_laplace = aplicando_laplace(prob, todas_palavras_relevantes)\r\n",
    "        prob_relevante *= prob_laplace\r\n",
    "    probRtweet = prob_relevante*probR\r\n",
    "    prob_irrelevante = 1\r\n",
    "    for palavra in lista_tweet:\r\n",
    "        prob = probDadoconj(palavra, tabela_irrelevante, todas_palavras_irrelevantes)\r\n",
    "        prob_laplace = aplicando_laplace(prob, todas_palavras_irrelevantes)\r\n",
    "        prob_irrelevante *= prob_laplace\r\n",
    "    probIRtweet = prob_irrelevante*probIR\r\n",
    "    if probRtweet < probIRtweet: \r\n",
    "        return 0 #Irrelevante\r\n",
    "    else: \r\n",
    "        return 1 #Relevante\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando a função na base de treinamento (PRIEMIRO TESTE): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Treinamento</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n      <th>Classificacao_Naive_Bayes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tô vendo la casa papel mdssss primeiro ep tira...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>agora vou assistir lá casa papel dormir porq a...</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dedo coçando pra assistir lá casa papel espera...</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>la casa papel faz torcer pros bandidos</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la casa papel acabou comigo encontro desidrata...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>tô aqui assistindo la casa papel ler todos spo...</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>achei nenhuma morte la casa papel ia superar n...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>caralho to chorando igual vagabunda porra la c...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>cara nunca chorei tanto quanto chorei olhando ...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>caralhos la casa papel</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 3 columns</p>\n</div>",
      "text/plain": "                                           Treinamento  \\\n0    tô vendo la casa papel mdssss primeiro ep tira...   \n1    agora vou assistir lá casa papel dormir porq a...   \n2    dedo coçando pra assistir lá casa papel espera...   \n3               la casa papel faz torcer pros bandidos   \n4    la casa papel acabou comigo encontro desidrata...   \n..                                                 ...   \n295  tô aqui assistindo la casa papel ler todos spo...   \n296  achei nenhuma morte la casa papel ia superar n...   \n297  caralho to chorando igual vagabunda porra la c...   \n298  cara nunca chorei tanto quanto chorei olhando ...   \n299                             caralhos la casa papel   \n\n     Classificação (relevante = 1, não relevante = 0)  \\\n0                                                 1.0   \n1                                                 0.0   \n2                                                 0.0   \n3                                                 1.0   \n4                                                 1.0   \n..                                                ...   \n295                                               0.0   \n296                                               1.0   \n297                                               1.0   \n298                                               1.0   \n299                                               1.0   \n\n     Classificacao_Naive_Bayes  \n0                            1  \n1                            0  \n2                            0  \n3                            1  \n4                            1  \n..                         ...  \n295                          0  \n296                          1  \n297                          1  \n298                          1  \n299                          1  \n\n[300 rows x 3 columns]"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Classificacao_Naive_Bayes'] = train.Treinamento.apply(Classificacao)\r\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia na base de treinamento foi de: 94.33333333333334%\n"
     ]
    }
   ],
   "source": [
    "#Porcentagem de acerto no conjunto de Treino:\r\n",
    "\r\n",
    "verdadeiros_positivos_train=train.loc[(train['Classificacao_Naive_Bayes']==1)&(train['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "verdadeiros_negativos_train=train.loc[(train['Classificacao_Naive_Bayes']==0)&(train['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "print(f'A acurácia na base de treinamento foi de: {((verdadeiros_positivos_train+verdadeiros_negativos_train)/train.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### BASE DE TESTE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VERIFICANDO A PERFORMANCE DO CLASSIFICADOR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Teste</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n      <th>Classificacao_Naive_Bayes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>quero terminar ver nova parte la casa papel má...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>existe outra série mundo mexa comigo la casa p...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tá foda desviar todos spoilers la casa papel</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>todoroki_jun né tô sentindo lá casa papel</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la casa papel tão ruim consegui terminar so t ...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>respeito casal fav la casa papel morto literal...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>assistindo la casa papel poder falar mal mão_e...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>sexo kk veste roupa aí gente vai maratonar la ...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>deus final la casa papel…………</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>sexo rosto_com_sobrancelha_levantada naokkkkk ...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 3 columns</p>\n</div>",
      "text/plain": "                                                 Teste  \\\n0    quero terminar ver nova parte la casa papel má...   \n1    existe outra série mundo mexa comigo la casa p...   \n2         tá foda desviar todos spoilers la casa papel   \n3            todoroki_jun né tô sentindo lá casa papel   \n4    la casa papel tão ruim consegui terminar so t ...   \n..                                                 ...   \n195  respeito casal fav la casa papel morto literal...   \n196  assistindo la casa papel poder falar mal mão_e...   \n197  sexo kk veste roupa aí gente vai maratonar la ...   \n198                       deus final la casa papel…………   \n199  sexo rosto_com_sobrancelha_levantada naokkkkk ...   \n\n     Classificação (relevante = 1, não relevante = 0)  \\\n0                                                   0   \n1                                                   1   \n2                                                   1   \n3                                                   0   \n4                                                   1   \n..                                                ...   \n195                                                 0   \n196                                                 0   \n197                                                 0   \n198                                                 1   \n199                                                 0   \n\n     Classificacao_Naive_Bayes  \n0                            0  \n1                            1  \n2                            1  \n3                            1  \n4                            0  \n..                         ...  \n195                          1  \n196                          0  \n197                          0  \n198                          1  \n199                          0  \n\n[200 rows x 3 columns]"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Classificacao_Naive_Bayes'] = test['Teste'].apply(Classificacao)\r\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DESCRIÇÃO DA PERFORMANCE DO CLASSIFICADOR:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As contagens a seguir são feitas comparando os valores da coluna em que fizemos a classificação manualmente *\"Classificação (relevante = 1, não relevante = 0)\"* com os valores da coluna em que a classificação foi feita de maneira automática pela função criada anteriormente para nosso classificador *\"Classificacao_Naive_Bayes\"*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Porcentagem de verdadeiros positivos (mensagens relevantes e que são classificadas como relevantes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de verdadeiros positivos na base de teste foi de: 51.0%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_positivos=test.loc[(test['Classificacao_Naive_Bayes']==1)&(test['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "print(f'A porcentagem de verdadeiros positivos na base de teste foi de: {(verdadeiros_positivos/test.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Porcentagem de falsos positivos (mensagens irrelevantes e que são classificadas como relevantes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de falsos positivos na base de teste foi de: 22.5%\n"
     ]
    }
   ],
   "source": [
    "falsos_positivos=test.loc[(test['Classificacao_Naive_Bayes']==1)&(test['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "print(f'A porcentagem de falsos positivos na base de teste foi de: {(falsos_positivos/test.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Porcentagem de verdadeiros negativos (mensagens irrelevantes e que são classificadas como irrelevantes):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de verdadeiros negativos na base de teste foi de: 19.5%\n"
     ]
    }
   ],
   "source": [
    "verdadeiros_negativos=test.loc[(test['Classificacao_Naive_Bayes']==0)&(test['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "print(f'A porcentagem de verdadeiros negativos na base de teste foi de: {(verdadeiros_negativos/test.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Porcentagem de falsos negativos (mensagens relevantes e que são classificadas como irrelevantes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A porcentagem de falsos negativos na base de teste foi de: 7.000000000000001%\n"
     ]
    }
   ],
   "source": [
    "falsos_negativos=test.loc[(test['Classificacao_Naive_Bayes']==0)&(test['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "print(f'A porcentagem de falsos negativos na base de teste foi de: {(falsos_negativos/test.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Acurácia (mensagens corretamente classificadas, independente da categoria):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia na base de teste foi de: 70.5%\n"
     ]
    }
   ],
   "source": [
    "print(f'A acurácia na base de teste foi de: {((verdadeiros_positivos+verdadeiros_negativos)/test.shape[0])*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### CONCLUINDO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparativo qualitativo sobre os percentuais obtidos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mensagens com dupla negação e sarcasmo e a ingenuidade do Naïve Bayes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O programa Naïve Bayes pode ser caracterizadom como um sitema ingênuo, uma vez que dentro do calculo das probabilidades ele considera que cada palavra dentro dos tweets são independentes entre si, e que suas probabilidades de aparição independem completamente dos elementos que a antecedem ou a seguem. Isso porque o programa não conhece a língua portuguesa ou qualquer outra língua falada; a gramática e regras de escrita/fala não é conhecida pelo algorítmo, tudo que ele tem é um universo reduzido de palavras na língua portuguesa providos da base de 500 tweets selecionados no começo do projeto. Isso ajuda a explicar a falha que o programa apresenta ao se deparar com textos sarcásticos ou com outras figuras de linguagem.\n",
    "\n",
    "Tanto o sarcasmo quanto a dupla negação são elementos de linguagem que vêm do uso cotidiano e \"relaxado\" da língua. Não existe nenhuma regra formal concretizada que defina um padrão no uso de nenhuma delas.  \n",
    "\n",
    "Com isso dito começa a ficar claro como o programa reage à tweets sarcasticos ou que contém dupla negação. Como ele não conhece as características específicas da linguagem, o programa vai tratar a frase com o sentido **literal**, que muitas vezes é o oposto do que o sarcasmo ou a dupla negação querem dizer.  \n",
    "\n",
    "Por isso pode-se dizer que o programa pode ser flaho na hora de classificar tweets desse gênero, dada sua incapacidade de compreender as especificidades da língua portuguesa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependência da classificação manual para alimentação da base de dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como abordado anteriormente, o programa desconhece as especificidades das línguas, muitas vezes flahando em classificar corretamente expressões de linguagem, ditados populares ou figuras de linguagem.  \n",
    "\n",
    "Isso impossibilita que a classificação automática de novos tweets para a base de dados seja feita uma vez que a classificação errônea desses casos criaria uma incerteza e inconsistência na classificação dos demais que com o tempo seria propagada contribuido negativamente para a maiior acurácia e eficácia do programa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plano de expansão:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diferentes cenários de uso para o classificador Naive-Bayes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possíveis melhorias no classificador e como implementá-las:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ainda mais limpezas na base de dados:  \r\n",
    "    Além da limpeza de stopwords, poderíamos propor outras limpezas/transformações que não afetem a qualidade da informação.  \r\n",
    "    Alguns exemplos:  \r\n",
    "    - Stemming: \r\n",
    "    - Lemmatization:    \r\n",
    "- N-grams:\r\n",
    "- TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\r\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\r\n",
    "\r\n",
    "Para fazer esse item do Projeto, utilizamos a biblioteca scikit-learn (sklearn) que contém diversas funções úteis para a análise preditiva de dados. Em especial, utilizaremos a função train_test_split que divide listas e séries de dados em bases de treinamento e teste aleatoriamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder usar a função para dividir nossa base inteira em novas bases de treinamento e teste, primeiramente vamos unir as duas bases em uma única série a partir da função 'concat' do Pandas.  \r\n",
    "  \r\n",
    "Para que todos os tweets fiquem em um uma única coluna para que eles possam ser divididos novamente, precisamos renomear a coluna que descrevia se ele fazia parte do teste ou treinamento para um nome unificado 'Tweets'.  \r\n",
    "  \r\n",
    "Ademais, precisamos remover a coluna de classificação feita pelo nosso classificador ('Classificacao_Naive_Bayes'), para que ela possa ser feita novamente em cada uma das repetições do processo com base na nova base de treinamento.  \r\n",
    "  \r\n",
    "*Note que não precisamos aplicar as funções de limpeza novamente nas bases pois a base total de tweets já está sendo criada com as séries previamente limpas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tô vendo la casa papel mdssss primeiro ep tira...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>agora vou assistir lá casa papel dormir porq a...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dedo coçando pra assistir lá casa papel espera...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>la casa papel faz torcer pros bandidos</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la casa papel acabou comigo encontro desidrata...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>tô aqui assistindo la casa papel ler todos spo...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>achei nenhuma morte la casa papel ia superar n...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>caralho to chorando igual vagabunda porra la c...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>cara nunca chorei tanto quanto chorei olhando ...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>caralhos la casa papel</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 2 columns</p>\n</div>",
      "text/plain": "                                                Tweets  \\\n0    tô vendo la casa papel mdssss primeiro ep tira...   \n1    agora vou assistir lá casa papel dormir porq a...   \n2    dedo coçando pra assistir lá casa papel espera...   \n3               la casa papel faz torcer pros bandidos   \n4    la casa papel acabou comigo encontro desidrata...   \n..                                                 ...   \n295  tô aqui assistindo la casa papel ler todos spo...   \n296  achei nenhuma morte la casa papel ia superar n...   \n297  caralho to chorando igual vagabunda porra la c...   \n298  cara nunca chorei tanto quanto chorei olhando ...   \n299                             caralhos la casa papel   \n\n     Classificação (relevante = 1, não relevante = 0)  \n0                                                 1.0  \n1                                                 0.0  \n2                                                 0.0  \n3                                                 1.0  \n4                                                 1.0  \n..                                                ...  \n295                                               0.0  \n296                                               1.0  \n297                                               1.0  \n298                                               1.0  \n299                                               1.0  \n\n[300 rows x 2 columns]"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_para_concat = train\r\n",
    "train_para_concat = train_para_concat.rename(columns={\"Treinamento\": \"Tweets\"})\r\n",
    "train_para_concat =train_para_concat.drop(['Classificacao_Naive_Bayes'], axis=1)\r\n",
    "train_para_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>quero terminar ver nova parte la casa papel má...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>existe outra série mundo mexa comigo la casa p...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tá foda desviar todos spoilers la casa papel</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>todoroki_jun né tô sentindo lá casa papel</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la casa papel tão ruim consegui terminar so t ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>respeito casal fav la casa papel morto literal...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>assistindo la casa papel poder falar mal mão_e...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>sexo kk veste roupa aí gente vai maratonar la ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>deus final la casa papel…………</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>sexo rosto_com_sobrancelha_levantada naokkkkk ...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 2 columns</p>\n</div>",
      "text/plain": "                                                Tweets  \\\n0    quero terminar ver nova parte la casa papel má...   \n1    existe outra série mundo mexa comigo la casa p...   \n2         tá foda desviar todos spoilers la casa papel   \n3            todoroki_jun né tô sentindo lá casa papel   \n4    la casa papel tão ruim consegui terminar so t ...   \n..                                                 ...   \n195  respeito casal fav la casa papel morto literal...   \n196  assistindo la casa papel poder falar mal mão_e...   \n197  sexo kk veste roupa aí gente vai maratonar la ...   \n198                       deus final la casa papel…………   \n199  sexo rosto_com_sobrancelha_levantada naokkkkk ...   \n\n     Classificação (relevante = 1, não relevante = 0)  \n0                                                   0  \n1                                                   1  \n2                                                   1  \n3                                                   0  \n4                                                   1  \n..                                                ...  \n195                                                 0  \n196                                                 0  \n197                                                 0  \n198                                                 1  \n199                                                 0  \n\n[200 rows x 2 columns]"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_para_concat = test\r\n",
    "test_para_concat = test_para_concat.rename(columns={\"Teste\": \"Tweets\"})\r\n",
    "test_para_concat =test_para_concat.drop(['Classificacao_Naive_Bayes'], axis=1)\r\n",
    "test_para_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweets</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tô vendo la casa papel mdssss primeiro ep tira...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>agora vou assistir lá casa papel dormir porq a...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dedo coçando pra assistir lá casa papel espera...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>la casa papel faz torcer pros bandidos</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la casa papel acabou comigo encontro desidrata...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>respeito casal fav la casa papel morto literal...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>assistindo la casa papel poder falar mal mão_e...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>sexo kk veste roupa aí gente vai maratonar la ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>deus final la casa papel…………</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>sexo rosto_com_sobrancelha_levantada naokkkkk ...</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 2 columns</p>\n</div>",
      "text/plain": "                                                Tweets  \\\n0    tô vendo la casa papel mdssss primeiro ep tira...   \n1    agora vou assistir lá casa papel dormir porq a...   \n2    dedo coçando pra assistir lá casa papel espera...   \n3               la casa papel faz torcer pros bandidos   \n4    la casa papel acabou comigo encontro desidrata...   \n..                                                 ...   \n495  respeito casal fav la casa papel morto literal...   \n496  assistindo la casa papel poder falar mal mão_e...   \n497  sexo kk veste roupa aí gente vai maratonar la ...   \n498                       deus final la casa papel…………   \n499  sexo rosto_com_sobrancelha_levantada naokkkkk ...   \n\n     Classificação (relevante = 1, não relevante = 0)  \n0                                                 1.0  \n1                                                 0.0  \n2                                                 0.0  \n3                                                 1.0  \n4                                                 1.0  \n..                                                ...  \n495                                               0.0  \n496                                               0.0  \n497                                               0.0  \n498                                               1.0  \n499                                               0.0  \n\n[500 rows x 2 columns]"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_inteira_tweets = pd.concat([train_para_concat, test_para_concat], ignore_index=True, sort=False)\r\n",
    "base_inteira_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separando a base inteira entre treinamento e teste 100 vezes e calculando a acurácia do classificador em cada uma das separações:\r\n",
    "  \r\n",
    "Em cada repetição do loop, a função train_test_split está sendo executada dividindo a base completa em novas bases de treinamento ('base_train') e teste ('base_test') mantendo a proporção de 200 tweets como teste (40%) e os outros 300 (60%) como treinamento, já que isso é especificado no parâmetro 'test_size' da função. O parâmetro 'random_state' com valor None garante que a cada vez que o loop repetir, uma nova divisão será feita, se ele recebesse um valor int específico a função faria a exata mesma divisão em todas as repetições do loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n",
      "<ipython-input-71-0c95f28b9264>:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\n"
     ]
    }
   ],
   "source": [
    "lista_acuracias = []\r\n",
    "for i in range(100):\r\n",
    "    #separando a base completa aleatoriamente entre train e test, mantendo a proporção de 200 tweets como teste (40%) e os outros 300 (60%) como treinamento\r\n",
    "    base_train, base_test = train_test_split(base_inteira_tweets, test_size=0.4, random_state=None)\r\n",
    "    #criando filtros para separar os tweets relevantes dos irrelevantes\r\n",
    "    filtro_nao_relevante = base_train['Classificação (relevante = 1, não relevante = 0)']==0\r\n",
    "    filtro_relevante = base_train['Classificação (relevante = 1, não relevante = 0)']==1\r\n",
    "\r\n",
    "    #separando em dois DFs diferentes os tweets relevantes e irrelevantes\r\n",
    "    relevantes_train = base_train[filtro_relevante]\r\n",
    "    nao_relevantes_train = base_train[filtro_nao_relevante]\r\n",
    "\r\n",
    "    #criando uma string grande para armazenar todos os tweets de cada classificação\r\n",
    "    relevantes_train_txt = ''\r\n",
    "    for tweet in relevantes_train['Tweets']:\r\n",
    "        relevantes_train_txt += \" \"\r\n",
    "        relevantes_train_txt += str(tweet)\r\n",
    "    nao_relevantes_train_txt = ''\r\n",
    "    for tweet in nao_relevantes_train['Tweets']:\r\n",
    "        nao_relevantes_train_txt += \" \"\r\n",
    "        nao_relevantes_train_txt += str(tweet)\r\n",
    "    \r\n",
    "    #organizando os tweets em listas de palavras e pandas Series \r\n",
    "\r\n",
    "    #fazendo a lista com todas as palavaras dos tweets\r\n",
    "    todas_palavras_relevantes = relevantes_train_txt.split()\r\n",
    "    todas_palavras_irrelevantes = nao_relevantes_train_txt.split()\r\n",
    "\r\n",
    "    #transformando a lista em uma panda Series\r\n",
    "    serie_relevante = pd.Series(todas_palavras_relevantes)\r\n",
    "    serie_irrelevante = pd.Series(todas_palavras_irrelevantes)\r\n",
    "\r\n",
    "    tabela_relevante = serie_relevante.value_counts()\r\n",
    "    tabela_irrelevante = serie_irrelevante.value_counts()\r\n",
    "\r\n",
    "    #organizando o conjunto universo de todas as palavras\r\n",
    "\r\n",
    "    palavras = relevantes_train_txt + nao_relevantes_train_txt\r\n",
    "    todas_palavras = palavras.split()\r\n",
    "    serie_palavras = pd.Series(todas_palavras)\r\n",
    "    tabela_palavras = serie_palavras.value_counts(normalize=True)\r\n",
    "\r\n",
    "\r\n",
    "    palavras_sem_repeticao = []\r\n",
    "    for e in todas_palavras:\r\n",
    "        if e not in palavras_sem_repeticao:\r\n",
    "            palavras_sem_repeticao.append(e)\r\n",
    "    \r\n",
    "    #calculando a probabilidade de um tweet ser relevante ou irrelevante\r\n",
    "    probR = len(serie_relevante)/len(serie_palavras)\r\n",
    "    probIR = len(serie_irrelevante)/len(serie_palavras)\r\n",
    "\r\n",
    "    base_test['Classificacao_Naive_Bayes'] = base_test['Tweets'].apply(Classificacao)\r\n",
    "    verdadeiros_positivos=base_test.loc[(base_test['Classificacao_Naive_Bayes']==1)&(base_test['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "    verdadeiros_negativos=base_test.loc[(base_test['Classificacao_Naive_Bayes']==0)&(base_test['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "    acuracia = ((verdadeiros_positivos+verdadeiros_negativos)/base_test.shape[0])*100\r\n",
    "    lista_acuracias.append(acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "100"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Demonstrando que o processo foi repetido 100 vezes e, portanto, temos 100 contagens de acurácias\r\n",
    "len(lista_acuracias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0.5, 0, 'acurácia [em %]')"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": "<Figure size 1440x1440 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 20))\r\n",
    "plt.hist(lista_acuracias, bins=10, edgecolor='white', color='crimson', density=True)\r\n",
    "plt.title('Histograma de acurácia do classificador em 100 simulações')\r\n",
    "plt.ylabel('densidade')\r\n",
    "plt.xlabel('acurácia [em %]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96eb50e1d44aed467dc8f759cb08c32fbfa9babcf79c554e2d0e5feb04653a10"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}