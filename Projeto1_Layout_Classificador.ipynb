{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Arthur Cisotto Machado\r\n",
    "\r\n",
    "Nome: Alessandra Yumi Carvalho Ogawa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONTEXTO DO PROJETO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A empresa de streaming *Netflix* em parceria com o estúdio espanhol *Vancouver Media* deseja saber e analisar como a audiencia está reagindo a série de sucesso *La Casa de Papel* na rede social Twitter. \n",
    "O projeto exige a criação de um programa que consiga classificar os tweets entre **relevantes** ou **irrelevantes** para a análise da empresa.\n",
    "\n",
    "A classificação foi feita com o intúito de ajudar a área de marketing das duas empresas parceiras a acharem comentários que possam ser úteis em algum sentido estratégio para mudança de operações internas e também como fonte de *feedback* em relação ao conteúdo cinematográfico produzido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### CARREGANDO AS BIBLIOTECAS UTILIZADAS NO RPOGRAMA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import re \r\n",
    "import emoji\r\n",
    "from emoji import UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "/Users/alessandrayumiogawa/Documents/INSPER/INSPER - 2A/C-DADOS/P1_CDados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\r\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### FUNÇÃO DE LIMPEZA DOS TWEETS:\n",
    "- tira sinais de pontuação irrelevantes para o texto;\n",
    "- exculi repetição de emoji;\n",
    "- substitui emoji por seu código;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/re.html#\n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "\n",
    "    punctuation = '[”/-@\\\\n:;?\\\"\\'().,]' \n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    text_split = text_subbed.split()\n",
    "    return ' '.join(text_split).lower()\n",
    "\n",
    "def limpa_emoji(tweet):\n",
    "    \n",
    "    modified=' '.join(emoji.get_emoji_regexp().split(tweet))\n",
    "    modified=modified.split()\n",
    "    for i,emoji1 in enumerate(modified):\n",
    "        if emoji1 in UNICODE_EMOJI['pt']:\n",
    "            modified[i]=UNICODE_EMOJI['pt'][emoji1].replace(':','')\n",
    "        elif emoji1 in UNICODE_EMOJI['en']:\n",
    "            modified[i]=UNICODE_EMOJI['en'][emoji1].replace(':','')\n",
    "        else:\n",
    "            continue\n",
    "    modified=' '.join(modified)\n",
    "        \n",
    "    return modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpeza_e_emoji(tweet):                 #compilado das duas funções em uma só para mais fácil aplicação\n",
    "    texto_filtrado = cleanup(tweet)\n",
    "    sem_emoji = limpa_emoji(texto_filtrado)\n",
    "    return sem_emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### CARREGANDO A BASE DE DADOS COM OS TWEETS CLASSIFICADOS COMO ***RELEVANTES*** E ***IRRELEVANTES*** MANUALMENTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'la casa de papel.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação do documento em dois DataFrames diferentes: **Treinamento** e **Teste**.\n",
    "\n",
    "- **Treinamento**: composto por 300 tweets classificados manualmente, será usado para *ensinar* o programa a classificar um tweets de acorodo com a sua relevância levando em conta as palavras em seu conteúdo.\n",
    "\n",
    "- **Teste**: composto por 200 tweets classificados manualmente, será usado para *testar* o programa classificador e comparar o resultado com a classificação feita à mão anteriormente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Treinamento</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tô vendo la casa de papel mdssss o primeiro ep...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>agora vou assistir lá casa de papel e dormir p...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dedo coçando pra assistir lá casa de papel mas...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>la casa de papel me faz torcer pros bandidos</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la casa de papel acabou comigo me encontro des...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                         Treinamento  \\\n0  tô vendo la casa de papel mdssss o primeiro ep...   \n1  agora vou assistir lá casa de papel e dormir p...   \n2  dedo coçando pra assistir lá casa de papel mas...   \n3       la casa de papel me faz torcer pros bandidos   \n4  la casa de papel acabou comigo me encontro des...   \n\n   Classificação (relevante = 1, não relevante = 0)  \n0                                               1.0  \n1                                               0.0  \n2                                               0.0  \n3                                               1.0  \n4                                               1.0  "
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train['Treinamento'] = train['Treinamento'].apply(limpeza_e_emoji) #aplicando a função de limpeza\n",
    "train.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBS**: a função de limpeza já foi aplicada no DataFrame de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Teste</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>quero terminar de ver a nova parte de la casa ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>não existe outra série no mundo que mexa comig...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tá foda de desviar de todos os spoilers de la ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>@todoroki_jun2 né tô me sentindo em lá casa de...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la casa de papel é tão ruim que nem consegui t...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                               Teste  \\\n0  quero terminar de ver a nova parte de la casa ...   \n1  não existe outra série no mundo que mexa comig...   \n2  tá foda de desviar de todos os spoilers de la ...   \n3  @todoroki_jun2 né tô me sentindo em lá casa de...   \n4  la casa de papel é tão ruim que nem consegui t...   \n\n   Classificação (relevante = 1, não relevante = 0)  \n0                                                 0  \n1                                                 1  \n2                                                 1  \n3                                                 0  \n4                                                 1  "
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\r\n",
    "test.head(5)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### CLASSIFICADOR AUTOMÁTICO DE SENTIMENTO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O filtro criado para a realização da classificação manual seguia o padrão especificado abaixo:\n",
    "\n",
    "**RELEVANTES**: As mensagens de texto com relevância mostravam a opinião e sentimentos, sejam eles positivos ou negativos, sobre a série.\n",
    "*Consideramos tweets relacionados a spoilers como relevantes pois eles também demonstram um forte sentimento que as pessoas possuem em relação à série.\n",
    "\n",
    "**IRRELEVANTES**: Classificamos como não relevantes tweets que não se encaixaram na nossa classificação de relevância, tweets que falavam sobre tópicos pessoais ou tweets que falavam sobre algum personagem específico da série.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### MONTANDO UM CLASSIFICADOR NAÏVE-BAYES:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PREPARANDO OS DADOS DO TREINAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando filtros para smeprar os tweets relevantes dos irrelevantes\n",
    "\n",
    "filtro_nao_relevante = train['Classificação (relevante = 1, não relevante = 0)']==0\n",
    "filtro_relevante = train['Classificação (relevante = 1, não relevante = 0)']==1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separando em dois DFs diferentes os tweets relevantes e irrelevantes\n",
    "\n",
    "relevantes_train = train[filtro_relevante]\n",
    "nao_relevantes_train = train[filtro_nao_relevante]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando uma sting grande para armazenar todos os tweets de cada classificação\n",
    "\n",
    "relevantes_train_txt = ''\n",
    "for tweet in relevantes_train['Treinamento']:\n",
    "    relevantes_train_txt += \" \"\n",
    "    relevantes_train_txt += str(tweet)\n",
    "\n",
    "nao_relevantes_train_txt = ''\n",
    "for tweet in nao_relevantes_train['Treinamento']:\n",
    "    nao_relevantes_train_txt += \" \"\n",
    "    nao_relevantes_train_txt += str(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organizando os tweets em lista de palavras e pandas Series \n",
    "\n",
    "#fazendo a lista com todas as palavaras dos tweets\n",
    "todas_palavras_relevantes = relevantes_train_txt.split()\n",
    "todas_palavras_irrelevantes = nao_relevantes_train_txt.split()\n",
    "\n",
    "#transformando a lista em uma panda Series\n",
    "serie_relevante = pd.Series(todas_palavras_relevantes)\n",
    "serie_irrelevante = pd.Series(todas_palavras_irrelevantes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PREPARANDO AS TABELAS DE FREQUÊNCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_relevante = serie_relevante.value_counts()\n",
    "tabela_irrelevante = serie_irrelevante.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organizando o conjunto universo de todas as palavras\n",
    "\n",
    "palavras = relevantes_train_txt + nao_relevantes_train_txt\n",
    "todas_palavras = palavras.split()\n",
    "serie_palavras = pd.Series(todas_palavras)\n",
    "tabela_palavras = serie_palavras.value_counts(normalize=True)\n",
    "palavras_sem_repeticao = set(todas_palavras_relevantes + todas_palavras_irrelevantes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MONTANDO AS PROBABILIDADES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculando a probabilidade de um tweet ser classificado como relevante ou irrelevante\n",
    "probR = len(serie_relevante)/len(serie_palavras)\n",
    "probIR = len(serie_irrelevante)/len(serie_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRIMEIRA FUNÇÃO: calculando a probabilidade de uma X aparecer dado um dos conjuntos (relevante ou irrelevante)\n",
    "\n",
    "def probDadoconj(palavra, prob_conj, lista_palavras_conj):\n",
    "    if palavra in lista_palavras_conj:\n",
    "        return prob_conj[palavra]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#exemplo: print(probDadoconj(\"la\", tabela_relevante, todas_palavras_relevantes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEGUNDA FUNÇÃO: aplicando a suavização de Laplace\n",
    "\n",
    "def aplicando_laplace(prob_dado_conj, lista_palavras_conj):\n",
    "    return (prob_dado_conj+1)/(len(lista_palavras_conj)+len(palavras_sem_repeticao))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNÇÃO FINAL: compilado das duas funções anteriores\n",
    "#essa funçã0 realiza duas vezes as funções escritas anteriormente e depois comparam seus resultados para classificar\n",
    "\n",
    "def Classificacao(tweet):\n",
    "    prob_relevante = 1\n",
    "    lista_tweet = tweet.split()\n",
    "    for palavra in lista_tweet:\n",
    "        prob = probDadoconj(palavra, tabela_relevante, todas_palavras_relevantes)\n",
    "        prob_laplace = aplicando_laplace(prob, todas_palavras_relevantes)\n",
    "        prob_relevante *= prob_laplace\n",
    "    probRtweet = prob_relevante*probR\n",
    "    prob_irrelevante = 1\n",
    "    for palavra in lista_tweet:\n",
    "        prob = probDadoconj(palavra, tabela_irrelevante, todas_palavras_irrelevantes)\n",
    "        prob_laplace = aplicando_laplace(prob, todas_palavras_irrelevantes)\n",
    "        prob_irrelevante *= prob_laplace\n",
    "    probIRtweet = prob_irrelevante*probIR\n",
    "    if probRtweet < probIRtweet: \n",
    "        return 0\n",
    "    else: \n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Treinamento</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n      <th>Classificacao_Naive_Bayes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tô vendo la casa de papel mdssss o primeiro ep...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>agora vou assistir lá casa de papel e dormir p...</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dedo coçando pra assistir lá casa de papel mas...</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>la casa de papel me faz torcer pros bandidos</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la casa de papel acabou comigo me encontro des...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>tô aqui assistindo la casa de papel mesmo depo...</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>296</th>\n      <td>eu achei que nenhuma morte de la casa de papel...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>caralho eu to chorando igual uma vagabunda com...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>cara eu nunca chorei tanto quanto eu chorei ol...</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>o que caralhos foi isso em la casa de papel</td>\n      <td>1.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>300 rows × 3 columns</p>\n</div>",
      "text/plain": "                                           Treinamento  \\\n0    tô vendo la casa de papel mdssss o primeiro ep...   \n1    agora vou assistir lá casa de papel e dormir p...   \n2    dedo coçando pra assistir lá casa de papel mas...   \n3         la casa de papel me faz torcer pros bandidos   \n4    la casa de papel acabou comigo me encontro des...   \n..                                                 ...   \n295  tô aqui assistindo la casa de papel mesmo depo...   \n296  eu achei que nenhuma morte de la casa de papel...   \n297  caralho eu to chorando igual uma vagabunda com...   \n298  cara eu nunca chorei tanto quanto eu chorei ol...   \n299        o que caralhos foi isso em la casa de papel   \n\n     Classificação (relevante = 1, não relevante = 0)  \\\n0                                                 1.0   \n1                                                 0.0   \n2                                                 0.0   \n3                                                 1.0   \n4                                                 1.0   \n..                                                ...   \n295                                               0.0   \n296                                               1.0   \n297                                               1.0   \n298                                               1.0   \n299                                               1.0   \n\n     Classificacao_Naive_Bayes  \n0                            1  \n1                            0  \n2                            0  \n3                            1  \n4                            1  \n..                         ...  \n295                          0  \n296                          1  \n297                          1  \n298                          1  \n299                          1  \n\n[300 rows x 3 columns]"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Classificacao_Naive_Bayes'] = train.Treinamento.apply(Classificacao)\r\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo foi de:  94.0 %\n"
     ]
    }
   ],
   "source": [
    "#Porcentagem de acerto de acerto no conjunto de Treino:\r\n",
    "\r\n",
    "tp=train.loc[(train['Classificacao_Naive_Bayes']==1)&(train['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\r\n",
    "tn=train.loc[(train['Classificacao_Naive_Bayes']==0)&(train['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\r\n",
    "print('A acurácia do modelo foi de: ',100*(tp+tn)/train.shape[0],'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de Teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Teste</th>\n      <th>Classificação (relevante = 1, não relevante = 0)</th>\n      <th>Classificacao_Naive_Bayes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>quero terminar de ver a nova parte de la casa ...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>não existe outra série no mundo que mexa comig...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tá foda de desviar de todos os spoilers de la ...</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>todoroki_jun né tô me sentindo em lá casa de p...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>la casa de papel é tão ruim que nem consegui t...</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>em respeito ao meu casal fav de la casa de pap...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>196</th>\n      <td>assistindo la casa de papel para poder falar m...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>197</th>\n      <td>sexo não kk veste a roupa aí que a gente vai m...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>198</th>\n      <td>meu deus o final de la casa de papel…………</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>199</th>\n      <td>sexo rosto_com_sobrancelha_levantada naokkkkk ...</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>200 rows × 3 columns</p>\n</div>",
      "text/plain": "                                                 Teste  \\\n0    quero terminar de ver a nova parte de la casa ...   \n1    não existe outra série no mundo que mexa comig...   \n2    tá foda de desviar de todos os spoilers de la ...   \n3    todoroki_jun né tô me sentindo em lá casa de p...   \n4    la casa de papel é tão ruim que nem consegui t...   \n..                                                 ...   \n195  em respeito ao meu casal fav de la casa de pap...   \n196  assistindo la casa de papel para poder falar m...   \n197  sexo não kk veste a roupa aí que a gente vai m...   \n198           meu deus o final de la casa de papel…………   \n199  sexo rosto_com_sobrancelha_levantada naokkkkk ...   \n\n     Classificação (relevante = 1, não relevante = 0)  \\\n0                                                   0   \n1                                                   1   \n2                                                   1   \n3                                                   0   \n4                                                   1   \n..                                                ...   \n195                                                 0   \n196                                                 0   \n197                                                 0   \n198                                                 1   \n199                                                 0   \n\n     Classificacao_Naive_Bayes  \n0                            0  \n1                            1  \n2                            1  \n3                            1  \n4                            0  \n..                         ...  \n195                          1  \n196                          1  \n197                          0  \n198                          1  \n199                          0  \n\n[200 rows x 3 columns]"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Teste'] = test['Teste'].apply(limpeza_e_emoji)\r\n",
    "test['Classificacao_Naive_Bayes'] = test['Teste'].apply(Classificacao)\r\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo foi de:  68.5 %\n"
     ]
    }
   ],
   "source": [
    "tp=test.loc[(test['Classificacao_Naive_Bayes']==1)&(test['Classificação (relevante = 1, não relevante = 0)']==1),:].shape[0]\n",
    "tn=test.loc[(test['Classificacao_Naive_Bayes']==0)&(test['Classificação (relevante = 1, não relevante = 0)']==0),:].shape[0]\n",
    "print('A acurácia do modelo foi de: ',100*(tp+tn)/test.shape[0],'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transformações que não afetem a qualidade da informação contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adição de mais tweets na base, conforme enunciado. (OBRIGATÓRIO PARA TRIOS, sem contar como item avançado)\n",
    "* EXPLICOU porquê não pode usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* PROPÔS diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGATÓRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8480431bb365df6bcb1c44b7387c7b698c6b108659e761b6ab654603c809c5e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd0dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}